{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6517eb2f",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142171e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "# IPython / Widgets\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "# Network Analysis\n",
    "import networkx as nx\n",
    "\n",
    "# Machine Learning & Clustering\n",
    "from sklearn.cluster import KMeans, SpectralClustering\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Time Series / Probabilistic Models\n",
    "from pydtmc import MarkovChain\n",
    "import pydtmc as dtmc\n",
    "from tslearn.metrics import dtw\n",
    "\n",
    "# Distance Metrics\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# Feature Engineering\n",
    "from feature_engine.outliers import OutlierTrimmer\n",
    "\n",
    "DATA_DIR = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81557248",
   "metadata": {},
   "source": [
    "### Terminal commands to install prerequisites\n",
    "\n",
    "```console\n",
    "conda create -n gogymi python=3.12 numpy pandas matplotlib seaborn plotly ipywidgets ipython nbformat networkx scikit-learn tslearn scipy -c conda-forge -y\n",
    "```\n",
    "\n",
    "```console\n",
    "conda activate gogymi\n",
    "pip install pydtmc feature-engine\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa2af6",
   "metadata": {},
   "source": [
    "# Research question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54198a47",
   "metadata": {},
   "source": [
    "## What is the typical learning trajectory of a student?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac104c1",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e3ea6e",
   "metadata": {},
   "source": [
    "### Load dataframes' relevant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = pd.read_csv(f'{DATA_DIR}/activity.csv')\n",
    "all_scores = pd.read_csv(f'{DATA_DIR}/all_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3910554",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = activities[['user_id', 'course_id', 'activity_type', 'activity_started', 'activity_completed']]\n",
    "all_scores = all_scores[['user_id', 'course', 'percentage']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e3eda",
   "metadata": {},
   "source": [
    "### Remove old dates, outliers, long  and missing durations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6da563",
   "metadata": {},
   "source": [
    "- Get only users that have score data\n",
    "- Exam is irrelevant because it is simple moodle-style pdf access\n",
    "- Access is always immediately followed by a relevant state such as course, lesson or quiz\n",
    "- Group progress concerns only teachers\n",
    "- Durations will be kept in timedelta(ns) to preserve granularity\n",
    "- Durations_minutes is calculated for visualizations and the trimming\n",
    "- Trim using typical IQR method and Tukey's rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only courses we have scores for\n",
    "activities = activities[activities['course_id'].isin(all_scores.course.unique())]\n",
    "# Drop irrelevant activity types\n",
    "activities = activities[~activities['activity_type'].isin(['exam','group_progress','access'])]\n",
    "\n",
    "# Calculate activity durations\n",
    "activities = activities.dropna(subset=['activity_started', 'activity_completed'])\n",
    "activities['activity_started'] = pd.to_datetime(activities['activity_started'], unit='s')\n",
    "activities['activity_completed'] = pd.to_datetime(activities['activity_completed'], unit='s')\n",
    "activities['duration'] = activities['activity_completed'] - activities['activity_started']\n",
    "\n",
    "# Filter out old dates and irrelevant long durations(more than 24h long means the person might have left and finished on another day)\n",
    "print(activities.shape)\n",
    "activities = activities[\n",
    "    (activities['duration'] >= pd.Timedelta(0)) &\n",
    "    (activities['duration'] <= pd.Timedelta(hours=24)) &\n",
    "    (activities['activity_started'].dt.year > 2022)\n",
    "]\n",
    "print(activities.shape)\n",
    "\n",
    "# Utility column in float64 for minutes (instead of the timedelta(ns) duration)\n",
    "activities['duration_minutes'] = activities['duration'].dt.total_seconds()/60\n",
    "\n",
    "activities_before = activities.copy()\n",
    "\n",
    "# Trim outliers\n",
    "trimmer = OutlierTrimmer(capping_method='iqr', tail='both', fold=1.5, variables=['duration_minutes'])\n",
    "activities = trimmer.fit_transform(activities)\n",
    "\n",
    "print(activities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93098f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2564f26e",
   "metadata": {},
   "source": [
    "### Visualize durations distribution before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2c707",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(\"Activity Duration Distributions (Before & After Outlier Removal)\", fontsize=16)\n",
    "\n",
    "sns.histplot(activities_before['duration_minutes'], bins=20, color='skyblue', ax=axes[0], kde=True)\n",
    "axes[0].set_title('Before Outlier Removal')\n",
    "axes[0].set_xlabel('Duration (minutes)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True)\n",
    "\n",
    "sns.histplot(activities['duration_minutes'], bins=20, color='orange', ax=axes[1], kde=True)\n",
    "axes[1].set_title('After Outlier Removal')\n",
    "axes[1].set_xlabel('Duration (minutes)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837e210",
   "metadata": {},
   "source": [
    "#### Dictionaries for relevant courses (`course_id` -> `name`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dc724b",
   "metadata": {},
   "source": [
    "Those are the only courses we are interested in, as they are the only ones covered by the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a225f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Scores cover: {all_scores.course.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad9076e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping course_id -> course name/short name\n",
    "\n",
    "class SmartMap(dict):\n",
    "    def __missing__(self, key):\n",
    "        return f\"Unknown({key})\"\n",
    "    \n",
    "course_map = SmartMap({\n",
    "    42 : 'Langzeitgymnasium maths',\n",
    "    3865 : 'Kurzzeitgymnasium maths',\n",
    "    5447 : 'Langzeitgymnasium essay',\n",
    "    2115 : 'Langzeitgymnasium text comprehension',\n",
    "    5009 : 'Kurzzeitgymnasium text comprehension',\n",
    "    3301 : 'Kurzzeitgymnasium essay',\n",
    "    1696 : 'Student site introduction',\n",
    "    8117 : 'Teacher site introduction'\n",
    "})\n",
    "\n",
    "course_map_short = SmartMap({\n",
    "    42 : 'LZG_M',\n",
    "    3865 : 'KZG_M',\n",
    "    5447 : 'LZG_E',\n",
    "    2115 : 'LZG_TC',\n",
    "    5009 : 'KZG_TC',\n",
    "    3301 : 'KZG_E',\n",
    "    1696 : 'SSI',\n",
    "    8117 : 'TSI'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc655f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities_copy = activities.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea8d6f",
   "metadata": {},
   "source": [
    "# Cook some dataframes for the clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa31c93d",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6086b",
   "metadata": {},
   "source": [
    "### Brewing of **zduration_sum**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe5a581",
   "metadata": {},
   "source": [
    "#### For each user, course, and activity type combination, we calculate the z-score relative to the distribution of all users for the same course and activity type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a43e32c",
   "metadata": {},
   "source": [
    "Using `user_agg` we can choose how we aggregate the durations in case a student has done an activity of the same type and course multiple times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fe8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zduration(df_in, user_agg='sum'):\n",
    "    \"\"\"\n",
    "    Compute z-score normalized duration for each user per (course_id, activity_type) pair.\n",
    "\n",
    "    Parameters:\n",
    "        df_in: pd.DataFrame with columns: user_id, course_id, activity_type, duration\n",
    "        user_agg: str, 'sum' or 'mean'\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with: user_id, course_id, activity_type, duration, mean_duration, std_duration, zscore_duration\n",
    "    \"\"\"\n",
    "\n",
    "    # 0. Copy as to not modify the input dataframe\n",
    "    df = df_in.copy(deep=True)\n",
    "\n",
    "    # 1. Aggregate per user per (course_id, activity_type)\n",
    "    user_activity = (\n",
    "        df.groupby(['user_id', 'course_id', 'activity_type'], as_index=False)\n",
    "          .agg({'duration': user_agg})\n",
    "    )\n",
    "\n",
    "    # 2. Compute mean and std per (course_id, activity_type)\n",
    "    stats = (\n",
    "        user_activity.groupby(['course_id', 'activity_type'])['duration']\n",
    "        .agg(['mean', 'std']).reset_index()\n",
    "        .rename(columns={'mean': 'mean_duration', 'std': 'std_duration'})\n",
    "    )\n",
    "\n",
    "    # 3. Merge\n",
    "    merged = user_activity.merge(stats, on=['course_id', 'activity_type'], how='left')\n",
    "\n",
    "    # 4. Z-score\n",
    "    merged['zscore_duration'] = (merged['duration'] - merged['mean_duration']) / merged['std_duration']\n",
    "\n",
    "    return merged[['user_id', 'course_id', 'activity_type', 'duration', 'mean_duration', 'std_duration', 'zscore_duration']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf45fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "zduration_sum = compute_zduration(activities, 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30cabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "zduration_sum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f939d62",
   "metadata": {},
   "source": [
    "### Brewing of gap_days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f1ea4",
   "metadata": {},
   "source": [
    "We compute the number of days between each user's active sessions to analyze engagement gaps.\n",
    "\n",
    "Using each user’s first activity per day, we calculate the gap between consecutive active days and store the result as a sorted list per user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3649a7df",
   "metadata": {},
   "source": [
    "#### i.e. gap_days contains for each user_id an ordered list of the amount of days elapsed between actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_daily_activity = activities.copy(deep=True)\n",
    "\n",
    "# Create new column for activity started day\n",
    "user_daily_activity['active_day'] = pd.to_datetime(user_daily_activity['activity_started'].dt.date)\n",
    "\n",
    "# Drop duplicates in user_id, active_day\n",
    "user_daily_activity.drop_duplicates(subset=['user_id', 'active_day'], inplace=True, keep='first')\n",
    "\n",
    "# Compute gaps between active days for each user\n",
    "user_daily_activity.sort_values(['user_id', 'active_day'], inplace=True)\n",
    "user_daily_activity['previous_day'] = user_daily_activity.groupby('user_id')['active_day'].shift(1)\n",
    "user_daily_activity['gap_days'] = (user_daily_activity['active_day'] - user_daily_activity['previous_day']).dt.days\n",
    "\n",
    "# Keep only relevnt columns\n",
    "columns = ['user_id', 'active_day', 'gap_days']\n",
    "user_daily_activity = user_daily_activity[columns]\n",
    "\n",
    "# Ceate a csv of user_ids, gap_days where gap_days is a list of the gaps (ignore nans) in increasing order. Use copies of the dataframes\n",
    "df = user_daily_activity.copy(deep=True)[['user_id', 'gap_days']]\n",
    "# Remove the first gap_days (nan) for each user\n",
    "df.dropna(subset=['gap_days'], inplace=True)\n",
    "# Group by user_id and aggregate the gap_days into a list\n",
    "df = df.groupby('user_id')['gap_days'].apply(lambda x: list(x)).reset_index()\n",
    "# Sort the gap_days list for each user\n",
    "df['gap_days'] = df['gap_days'].apply(lambda x: sorted(x))\n",
    "\n",
    "gap_days = df.copy(deep=True)\n",
    "\n",
    "# Save to csv\n",
    "gap_days.to_csv(f'{DATA_DIR}/user_gap_days.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f1af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_days.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282b708",
   "metadata": {},
   "source": [
    "### Brewing of user_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7be696",
   "metadata": {},
   "source": [
    "The key idea of **user_chains** (which is a dictionary user_id -> corresponding pydtmc MarkovChain) is to compactly represent each student's learning journey on the platform.\n",
    "\n",
    "Each MarkovChain's states are pairs of **activity_type** and **course_id** (we call them **activity_state**) with transition probabilities to each other and themselves.\n",
    "\n",
    "We index them via dictionary **state_to_idx** (whose inverse is dictionary **idx_to_state**), shift in order to get **next_state_idx**, calculate transition matrices, prune unvisited states and finally initialize the dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea87dd4",
   "metadata": {},
   "source": [
    "#### Create transition matrices for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = activities.copy()\n",
    "\n",
    "transitions.sort_values(by=['user_id', 'activity_started'], ascending=True, inplace=True)\n",
    "\n",
    "# Build activity_state = (activity_type, course_id) and log durations where possible\n",
    "transitions['activity_state'] = transitions['activity_type'] + '_' + transitions['course_id'].map(course_map_short).fillna('Unknown')\n",
    "\n",
    "\n",
    "# Index states numerically\n",
    "state_to_idx = {s: i for i, s in enumerate(transitions['activity_state'].unique())}\n",
    "transitions['state_idx'] = transitions['activity_state'].map(state_to_idx)\n",
    "\n",
    "# Log subsequent states into a separate column\n",
    "transitions['next_state_idx'] = transitions.groupby('user_id')['state_idx'].shift(-1)\n",
    "transitions = transitions.dropna(subset=['next_state_idx']).copy()\n",
    "transitions['next_state_idx'] = transitions['next_state_idx'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "all_states = transitions['activity_state'].unique().tolist()\n",
    "n_states = len(all_states)\n",
    "\n",
    "final_transitions = transitions[['user_id', 'activity_state', 'state_idx', 'next_state_idx']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735203a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transitions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ec925",
   "metadata": {},
   "source": [
    "There shouldn't actually be any 'Unknown' thanks to preprocessing, verify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_transitions['activity_state'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper dictionary\n",
    "idx_to_state = {i: name for name, i in state_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08addfd9",
   "metadata": {},
   "source": [
    "#### Prune user matrices to only contain states between which transitions exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219fd1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# total number of possible states\n",
    "n_states = max(\n",
    "    final_transitions['state_idx'].max(),\n",
    "    final_transitions['next_state_idx'].max()\n",
    ") + 1\n",
    "\n",
    "def make_pruned_absorbing_P(df):\n",
    "    # 1) build full count‐matrix\n",
    "    counts = pd.crosstab(df['state_idx'], df['next_state_idx'])\n",
    "    counts = counts.reindex(\n",
    "        index=range(n_states),\n",
    "        columns=range(n_states),\n",
    "        fill_value=0\n",
    "    )\n",
    "\n",
    "    # 2) pick any state that appears as from‐state OR to‐state\n",
    "    used = (counts.sum(axis=1) > 0) | (counts.sum(axis=0) > 0)\n",
    "    used_states = counts.index[used]     # these are the original idxs we keep\n",
    "\n",
    "    # 3) prune to only those\n",
    "    pruned = counts.loc[used_states, used_states].copy()\n",
    "\n",
    "    # 4) make any zero‐row into an absorbing self‐loop\n",
    "    zero_rows = pruned.sum(axis=1) == 0\n",
    "    for s in zero_rows[zero_rows].index:\n",
    "        pruned.at[s, s] = 1\n",
    "\n",
    "    # 5) normalize each row\n",
    "    P = pruned.div(pruned.sum(axis=1), axis=0)\n",
    "    return P\n",
    "\n",
    "# apply per user\n",
    "user_pruned_matrices = {\n",
    "    uid: make_pruned_absorbing_P(g)\n",
    "    for uid, g in final_transitions.groupby('user_id')\n",
    "}\n",
    "\n",
    "# now for our sanity-check user 18 who has as transitions only 10→10(3 times) and 10→11(once):\n",
    "P_example = user_pruned_matrices[18]\n",
    "print(P_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d142a6",
   "metadata": {},
   "source": [
    "#### Create a Markov Chain for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_chains = {}\n",
    "\n",
    "for uid in user_pruned_matrices:\n",
    "    pruned_matrix = user_pruned_matrices[uid]\n",
    "    if pruned_matrix.shape[0]>1:\n",
    "        user_chains[uid] = MarkovChain(pruned_matrix, [idx_to_state[i] for i in pruned_matrix.index.tolist()])\n",
    "    else:\n",
    "        user_chains.pop(uid, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cefe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MarkovChain(user_pruned_matrices[18], [idx_to_state[i] for i in user_pruned_matrices[18].index.tolist()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc84fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a5eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transitions.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69969a37",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399a8568",
   "metadata": {},
   "source": [
    "### Create zscores per course for each user, course pair, keep percentages for visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = all_scores.copy()\n",
    "df[\"zscore\"] = df.groupby(\"course\")[\"percentage\"].transform(lambda x: (x - x.mean()) / x.std(ddof=0))\n",
    "zscores = df.rename(columns={'course': 'course_id'})\n",
    "\n",
    "zscores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9ea6e",
   "metadata": {},
   "source": [
    "# Some visualizations - for pallette cleansing and to orient before clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f05a30",
   "metadata": {},
   "source": [
    "## Some stats of durations on per course, activity type basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e57d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_median_duration = activities.groupby(['course_id', 'activity_type'])['duration'].median().reset_index()\n",
    "print(course_median_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345a3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-generated visualization\n",
    "\n",
    "def plot_course_durations(df_median, course_map_short):\n",
    "    # Prepare the data\n",
    "    df_median = df_median.copy()\n",
    "    df_median['duration_sec'] = df_median['duration'].dt.total_seconds()\n",
    "    \n",
    "    total_durations = df_median.groupby('course_id')['duration_sec'].sum()\n",
    "    max_total_duration = total_durations.max()\n",
    "\n",
    "    # Color map for activities\n",
    "    activity_types = sorted(df_median['activity_type'].unique())\n",
    "    cmap = plt.get_cmap('Set2')\n",
    "    colors = cmap(np.linspace(0, 1, len(activity_types)))\n",
    "    color_map = dict(zip(activity_types, colors))\n",
    "\n",
    "    # Plot settings\n",
    "    courses = total_durations.sort_values(ascending=False).index\n",
    "    n_courses = len(courses)\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(n_courses / n_cols))\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, course_id in enumerate(courses):\n",
    "        ax = axes[idx]\n",
    "        course_data = df_median[df_median['course_id'] == course_id]\n",
    "        durations = course_data['duration_sec'].values\n",
    "        labels = course_data['activity_type'].values\n",
    "\n",
    "        total_duration = durations.sum()\n",
    "        course_fraction = total_duration / max_total_duration\n",
    "        max_angle = 360 * course_fraction  # Total filled angle for this course\n",
    "\n",
    "        # Compute sizes in angles instead of fractions of 1\n",
    "        sizes = durations / total_duration * max_angle\n",
    "\n",
    "        start_angle = 90\n",
    "        for label, size in zip(labels, sizes):\n",
    "            ax.pie(\n",
    "                [size, 360 - size], \n",
    "                colors=[color_map[label], (0, 0, 0, 0)],  # Transparent for remaining part\n",
    "                startangle=start_angle, \n",
    "                radius=1,\n",
    "                counterclock=False,\n",
    "                wedgeprops=dict(width=0.3, edgecolor='white')\n",
    "            )\n",
    "            start_angle -= size  # Update start angle for next segment\n",
    "\n",
    "        # Draw the remaining transparent gap (optional light gray)\n",
    "        if course_fraction < 1:\n",
    "            ax.pie(\n",
    "                [360 * (1 - course_fraction), 360 * course_fraction],\n",
    "                colors=['#f0f0f0', (0, 0, 0, 0)],\n",
    "                startangle=90 - max_angle,\n",
    "                radius=1,\n",
    "                counterclock=False,\n",
    "                wedgeprops=dict(width=0.3, edgecolor='white')\n",
    "            )\n",
    "\n",
    "        # Add center text\n",
    "        course_name = course_map_short.get(course_id, course_id)\n",
    "        total_hours = int(total_duration // 3600)\n",
    "        total_minutes = int((total_duration % 3600) // 60)\n",
    "        ax.text(0, 0.1, course_name, ha='center', va='center', fontsize=12, weight='bold')\n",
    "        ax.text(0, -0.1, f\"{total_hours}h {total_minutes}m\", ha='center', va='center', fontsize=10)\n",
    "        \n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Remove unused subplots\n",
    "    for j in range(idx + 1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    # Add Legend\n",
    "    legend_patches = [mpatches.Patch(color=color_map[act], label=act) for act in activity_types]\n",
    "    fig.legend(\n",
    "        handles=legend_patches, \n",
    "        loc='upper right', \n",
    "        fontsize=10, \n",
    "        title='Activity Types'\n",
    "    )\n",
    "    plt.title(\"Course Durations\", fontsize=16, loc='center')\n",
    "\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6cfe69",
   "metadata": {},
   "source": [
    "### Durations per type for each course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44946e2b",
   "metadata": {},
   "source": [
    "#### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b7098",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_course_durations(course_median_duration, course_map_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801670ed",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52615a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_course_durations(activities.groupby(['course_id', 'activity_type'])['duration'].mean().reset_index(), course_map_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b1368d",
   "metadata": {},
   "source": [
    "### Some sanity-check prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b570be",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_median_duration.activity_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b5abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1571c53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679f5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_median_duration.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6d540",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_median_duration.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d272957",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6281c0",
   "metadata": {},
   "source": [
    "#### Limit to only intersection of users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abf2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zduration_users = set(zduration_sum['user_id'])\n",
    "gap_days_users = set(gap_days['user_id'])\n",
    "user_chains_users = set(user_chains.keys())\n",
    "\n",
    "# Find the intersection\n",
    "common_users = zduration_users & gap_days_users & user_chains_users\n",
    "\n",
    "# Filter each dataframe/dict to only the common users\n",
    "zduration_sum = zduration_sum[zduration_sum['user_id'].isin(common_users)]\n",
    "gap_days = gap_days[gap_days['user_id'].isin(common_users)]\n",
    "user_chains = {k: v for k, v in user_chains.items() if k in common_users}\n",
    "\n",
    "common_users = sorted(common_users)\n",
    "\n",
    "# Print the number of users in the intersection\n",
    "print(f'Number of users in all three: {len(common_users)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap dataframes we will be using after processing\n",
    "\n",
    "# Clustering inputs\n",
    "zduration_sum\n",
    "gap_days\n",
    "user_chains\n",
    "\n",
    "# Validation via\n",
    "zscores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abee313",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d78b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- Example 2: Expanded Graph Population ----------\n",
    "\n",
    "# 1) Build the graph with more users\n",
    "G = nx.Graph()\n",
    "nodes = ['alice', 'bob', 'carol', 'dave', 'eve', 'joe', 'gina']\n",
    "G.add_nodes_from(nodes)\n",
    "\n",
    "# 2) Add edges (only the alice–bob path edges will be highlighted)\n",
    "edges = [\n",
    "    ('alice', 'carol', 0.4),\n",
    "    ('carol', 'dave', 0.3),\n",
    "    ('dave', 'bob', 0.5),\n",
    "    ('alice', 'eve', 0.8),\n",
    "    ('eve', 'joe', 0.6),\n",
    "    ('joe', 'gina', 0.7),\n",
    "    ('gina', 'bob', 0.9),\n",
    "    ('carol', 'eve', 0.2),\n",
    "    ('dave', 'joe', 0.4)\n",
    "]\n",
    "G.add_weighted_edges_from(edges)\n",
    "\n",
    "# 3) Compute the shortest path between alice and bob\n",
    "shortest_path = nx.shortest_path(G, 'alice', 'bob', weight='weight')\n",
    "path_edges = list(zip(shortest_path, shortest_path[1:]))\n",
    "\n",
    "# 4) Prepare layout and styling\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "# Node drawing\n",
    "nx.draw_networkx_nodes(\n",
    "    G, pos,\n",
    "    node_size=800,\n",
    "    node_color='skyblue',\n",
    "    edgecolors='k'\n",
    ")\n",
    "nx.draw_networkx_labels(G, pos, font_size=12)\n",
    "\n",
    "# Edge drawing: highlight the shortest-path edges in red, others in light gray\n",
    "edge_colors = [\n",
    "    'firebrick' if (u, v) in path_edges or (v, u) in path_edges else 'lightgray'\n",
    "    for u, v in G.edges()\n",
    "]\n",
    "edge_widths = [\n",
    "    4 if (u, v) in path_edges or (v, u) in path_edges else 1\n",
    "    for u, v in G.edges()\n",
    "]\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos,\n",
    "    width=edge_widths,\n",
    "    edge_color=edge_colors\n",
    ")\n",
    "\n",
    "# 5) Label only the edges on the shortest path\n",
    "path_edge_labels = {\n",
    "    (u, v): f\"{G[u][v]['weight']:.2f}\"\n",
    "    for u, v in path_edges\n",
    "}\n",
    "nx.draw_networkx_edge_labels(\n",
    "    G, pos,\n",
    "    edge_labels=path_edge_labels,\n",
    "    font_size=12\n",
    ")\n",
    "\n",
    "# 6) Title and display\n",
    "plt.title('When no common states (Alice–Bob shortest path)', fontsize=16)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96803db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# --- Define the Markov chains (already tuned for α·JS + (1–α)·penalty ≈ 0.4) ---\n",
    "states1 = ['A', 'B', 'C']\n",
    "P1 = np.array([\n",
    "    [0.0, 0.7, 0.3],\n",
    "    [0.0, 0.0, 1.0],\n",
    "    [1.0, 0.0, 0.0]\n",
    "])\n",
    "states2 = ['B', 'C', 'D']\n",
    "P2 = np.array([\n",
    "    [0.17, 0.83, 0.0],\n",
    "    [0.2,  0.7,  0.1],\n",
    "    [0.0,  1.0,  0.0]\n",
    "])\n",
    "\n",
    "# Compute JS and penalty\n",
    "common = set(states1) & set(states2)\n",
    "idx1 = [states1.index(s) for s in common]\n",
    "idx2 = [states2.index(s) for s in common]\n",
    "subP1 = P1[np.ix_(idx1, idx1)]\n",
    "subP2 = P2[np.ix_(idx2, idx2)]\n",
    "js_vals = []\n",
    "for rp, rq in zip(subP1, subP2):\n",
    "    if rp.sum() > 0 and rq.sum() > 0:\n",
    "        p = rp / rp.sum()\n",
    "        q = rq / rq.sum()\n",
    "        js_vals.append(max(jensenshannon(p, q, base=2), 0))\n",
    "js = float(np.nanmean(js_vals)) if js_vals else 1.0\n",
    "pen = 1 - (len(common) / len(set(states1) | set(states2)))\n",
    "distance = 0.5 * js + 0.5 * pen\n",
    "\n",
    "# Node positions (triangle layout)\n",
    "pos1 = {'A': (-1, 0), 'B': (0, 1.1), 'C': (1, 0)}\n",
    "pos2 = {'B': (-1, 0), 'C': (0, 1.1), 'D': (1, 0)}\n",
    "\n",
    "# --- Plotting ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5), dpi=120)\n",
    "for ax, states, P, pos, title in zip(\n",
    "    axes, [states1, states2], [P1, P2], [pos1, pos2], ['Alice', 'Carol']\n",
    "):\n",
    "    G = nx.DiGraph()\n",
    "    weights = {}\n",
    "    for i, u in enumerate(states):\n",
    "        for j, v in enumerate(states):\n",
    "            w = P[i, j]\n",
    "            if w > 0:\n",
    "                G.add_edge(u, v, weight=w)\n",
    "                weights[(u, v)] = w\n",
    "\n",
    "    # Draw nodes\n",
    "    node_colors = ['tab:green' if s in common else 'lightgray' for s in states]\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, ax=ax, node_color=node_colors,\n",
    "        node_size=950, edgecolors='k', linewidths=1.5\n",
    "    )\n",
    "    nx.draw_networkx_labels(\n",
    "        G, pos, ax=ax, font_size=15, font_weight='bold'\n",
    "    )\n",
    "\n",
    "    # Draw edges\n",
    "    for (u, v), w in weights.items():\n",
    "        rad = 0.23 if (v, u) in weights and u != v else 0.0\n",
    "        xytext = np.array(pos[u]) * 0.92\n",
    "        xy = np.array(pos[v]) * 0.92\n",
    "        ax.annotate(\n",
    "            \"\", xy=xy, xytext=xytext,\n",
    "            arrowprops=dict(\n",
    "                arrowstyle='-|>,head_width=0.28,head_length=0.40',\n",
    "                lw=2.2,\n",
    "                color='k',\n",
    "                connectionstyle=f\"arc3,rad={rad}\"\n",
    "            )\n",
    "        )\n",
    "        # Draw label\n",
    "        label_pos = 0.55\n",
    "        x_lab = pos[u][0] * (1-label_pos) + pos[v][0] * label_pos\n",
    "        y_lab = pos[u][1] * (1-label_pos) + pos[v][1] * label_pos\n",
    "        ax.text(\n",
    "            x_lab, y_lab, f\"{w:.2f}\",\n",
    "            fontsize=12, fontweight='bold',\n",
    "            ha='center', va='center',\n",
    "            bbox=dict(boxstyle='round,pad=0.23', fc='white', ec='none')\n",
    "        )\n",
    "\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.axis('off')\n",
    "\n",
    "# --- Legend and summary\n",
    "common_line = plt.Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='tab:green', markersize=8)\n",
    "unique_line = plt.Line2D([0], [0], marker='o', color='w',\n",
    "                         markerfacecolor='lightgray', markersize=8)\n",
    "fig.legend(handles=[common_line, unique_line],\n",
    "           labels=['Common States', 'Unique States'],\n",
    "           loc='upper center', ncol=2, frameon=False, fontsize=12)\n",
    "fig.text(0.5, 0.05,\n",
    "         f\"JS = {js:.2f}   •   Penalty = {pen:.2f}   •   α·JS + (1–α)·penalty = {distance:.2f}\",\n",
    "         ha='center', fontsize=14, color='firebrick')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5618ba9a",
   "metadata": {},
   "source": [
    "#### Code used to validate robustness of metric using random data\n",
    "Uncomment last line to test for yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40ab4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_states(num_states, alphabet=None):\n",
    "    if alphabet is None:\n",
    "        import string\n",
    "        alphabet = list(string.ascii_lowercase)\n",
    "    import random\n",
    "    return random.sample(alphabet, num_states)\n",
    "\n",
    "def random_transition_matrix(size):\n",
    "    import numpy as np\n",
    "    mat = np.random.rand(size, size)\n",
    "    mat /= mat.sum(axis=1, keepdims=True)\n",
    "    return mat\n",
    "\n",
    "def generate_random_user_chains(common_users, min_states=3, max_states=6):\n",
    "    user_chains = {}\n",
    "    for user in common_users:\n",
    "        import random\n",
    "        n_states = random.randint(min_states, max_states)\n",
    "        states = random_states(n_states)\n",
    "        matrix = random_transition_matrix(n_states)\n",
    "        from pydtmc import MarkovChain\n",
    "        mc = MarkovChain(matrix, states)\n",
    "        user_chains[user] = mc\n",
    "    return user_chains\n",
    "\n",
    "# Example usage:\n",
    "# common_users = [f\"user_{i}\" for i in range(10)]\n",
    "# user_chains = generate_random_user_chains(common_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c87d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # def compute_js_and_penalty(c1, c2, alpha=0.5, pen_multiplier=1):\n",
    "# #     \"\"\"Returns α·JS + (1–α)·penalty for the common‐states subchain (or None).\"\"\"\n",
    "# #     common = set(c1.states) & set(c2.states)\n",
    "# #     if len(common) < 2:\n",
    "# #         return None\n",
    "\n",
    "# #     # Extract submatrices\n",
    "# #     idx1 = [c1.states.index(s) for s in common]\n",
    "# #     idx2 = [c2.states.index(s) for s in common]\n",
    "# #     P = c1.p[np.ix_(idx1, idx1)]\n",
    "# #     Q = c2.p[np.ix_(idx2, idx2)]\n",
    "\n",
    "# #     # JS divergence (row‐wise average)\n",
    "# #     js_vals = []\n",
    "# #     for row_p, row_q in zip(P, Q):\n",
    "# #         if row_p.sum() > 0 and row_q.sum() > 0:\n",
    "# #             # account for possible underflow\n",
    "# #             raw = jensenshannon(row_p, row_q, base=2)\n",
    "# #             js_vals.append(max(raw, 0.0))\n",
    "# #     js = float(np.nanmean(js_vals)) if js_vals else 1.0\n",
    "\n",
    "# #     # penalty = fraction of non-overlap\n",
    "# #     total_states = set(c1.states) | set(c2.states)\n",
    "# #     pen = 1 - (len(common) / len(total_states))\n",
    "# #     pen = pen*pen_multiplier\n",
    "\n",
    "# #     return alpha * js + (1 - alpha) * pen\n",
    "\n",
    "# def compute_js_and_penalty(c1, c2, alpha=0.5, pen_multiplier=1):\n",
    "#     common = set(c1.states) & set(c2.states)\n",
    "#     if len(common) < 2:\n",
    "#         # Too few states to do a meaningful JS; either skip or set js=0\n",
    "#         return None\n",
    "#     else:\n",
    "#         # Get sub‐matrices\n",
    "#         idx1 = [c1.states.index(s) for s in common]\n",
    "#         idx2 = [c2.states.index(s) for s in common]\n",
    "#         P = c1.p[np.ix_(idx1, idx1)]\n",
    "#         Q = c2.p[np.ix_(idx2, idx2)]\n",
    "\n",
    "#         js_vals = []\n",
    "#         for p_row, q_row in zip(P, Q):\n",
    "#             sp, sq = p_row.sum(), q_row.sum()\n",
    "#             if sp > 0 and sq > 0:\n",
    "#                 # normalize\n",
    "#                 p_norm = p_row / sp\n",
    "#                 q_norm = q_row / sq\n",
    "#                 # account for possible underflow\n",
    "#                 raw = jensenshannon(p_norm, q_norm, base=2)\n",
    "#                 js_vals.append(max(raw, 0.0))\n",
    "#         # only aggregate if we got something\n",
    "#         js = float(np.mean(js_vals)) if js_vals else 1.0\n",
    "\n",
    "#     # structural penalty as before\n",
    "#     total = set(c1.states) | set(c2.states)\n",
    "#     pen = 1 - (len(common) / len(total)) if total else 1.0\n",
    "#     pen = pen*pen_multiplier\n",
    "\n",
    "#     return alpha * js + (1 - alpha) * pen\n",
    "\n",
    "# def build_distance_matrix(user_chains, alpha=0.5, pen_multiplier=1):\n",
    "#     users = list(user_chains.keys())\n",
    "#     n = len(users)\n",
    "#     INF = float('inf')\n",
    "\n",
    "#     # 1) Initialize the “direct” distance lookup\n",
    "#     direct = { (u,v): (0.0 if u==v else INF)\n",
    "#                for u in users for v in users }\n",
    "\n",
    "#     # 2) Fill in distances for pairs with common states\n",
    "#     for u1, u2 in combinations(users, 2):\n",
    "#         dist = compute_js_and_penalty(user_chains[u1],\n",
    "#                                       user_chains[u2],\n",
    "#                                       alpha=alpha,\n",
    "#                                       pen_multiplier=pen_multiplier)\n",
    "#         if dist is not None:\n",
    "#             direct[(u1,u2)] = direct[(u2,u1)] = dist\n",
    "\n",
    "#     # 3) Build a graph whose edges are exactly those “direct” distances\n",
    "#     G = nx.Graph()\n",
    "#     G.add_nodes_from(users)\n",
    "#     for (u,v), w in direct.items():\n",
    "#         if u != v and w < INF:\n",
    "#             G.add_edge(u, v, weight=w)\n",
    "\n",
    "#     # 4) Compute all‐pairs shortest paths on G\n",
    "#     sp_lengths = dict(nx.all_pairs_dijkstra_path_length(G, weight='weight'))\n",
    "\n",
    "#     # 5) Assemble full DataFrame\n",
    "#     D = pd.DataFrame(INF, index=users, columns=users)\n",
    "#     for u in users:\n",
    "#         for v, d in sp_lengths[u].items():\n",
    "#             D.at[u, v] = d\n",
    "\n",
    "#     # 6) Count connected components (for reporting)\n",
    "#     n_components = nx.number_connected_components(G)\n",
    "\n",
    "#     return D, n_components\n",
    "\n",
    "# # -----------------------\n",
    "# # Example usage:\n",
    "\n",
    "# # Suppose you have:\n",
    "# #   user_chains = {\n",
    "# #       'alice': some_pydtmc.MarkovChain,\n",
    "# #       'bob':   some_pydtmc.MarkovChain,\n",
    "# #       ...\n",
    "# #   }\n",
    "\n",
    "# dist_matrix, components = build_distance_matrix(user_chains, alpha=0.2,pen_multiplier=1)\n",
    "# print(\"Distance matrix:\\n\", dist_matrix)\n",
    "# print(\"Connected components:\", components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eaac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global counters for reporting\n",
    "js_fallback_count = 0\n",
    "pen_fallback_count = 0\n",
    "js_eval_total = 0\n",
    "pen_eval_total = 0\n",
    "\n",
    "def compute_js_and_penalty(c1, c2, alpha=0.5, pen_multiplier=1):\n",
    "    \"\"\"Returns α·JS + (1–α)·penalty for the common‐states subchain (or None).\"\"\"\n",
    "    global js_fallback_count, pen_fallback_count\n",
    "    global js_eval_total, pen_eval_total\n",
    "\n",
    "    common = set(c1.states) & set(c2.states)\n",
    "    if len(common) < 2:\n",
    "        # Too few states to do a meaningful JS; either skip or set js=0\n",
    "        return None\n",
    "    else:\n",
    "        # Get sub‐matrices\n",
    "        idx1 = [c1.states.index(s) for s in common]\n",
    "        idx2 = [c2.states.index(s) for s in common]\n",
    "        P = c1.p[np.ix_(idx1, idx1)]\n",
    "        Q = c2.p[np.ix_(idx2, idx2)]\n",
    "\n",
    "        js_vals = []\n",
    "        for p_row, q_row in zip(P, Q):\n",
    "            sp, sq = p_row.sum(), q_row.sum()\n",
    "            if sp > 0 and sq > 0:\n",
    "                # normalize\n",
    "                p_norm = p_row / sp\n",
    "                q_norm = q_row / sq\n",
    "                # account for possible underflow\n",
    "                raw = jensenshannon(p_norm, q_norm, base=2)\n",
    "                js_vals.append(max(raw, 0.0))\n",
    "\n",
    "        # Track JS fallback usage\n",
    "        js_eval_total += 1\n",
    "        if js_vals:\n",
    "            js = float(np.mean(js_vals))\n",
    "        else:\n",
    "            js_fallback_count += 1\n",
    "            # print(\"Warning: js_vals is empty; using default JS = 1.0\")\n",
    "            js = 1.0\n",
    "\n",
    "    # structural penalty as before\n",
    "    total = set(c1.states) | set(c2.states)\n",
    "    pen_eval_total += 1\n",
    "    if total:\n",
    "        pen = 1 - (len(common) / len(total))\n",
    "    else:\n",
    "        pen_fallback_count += 1\n",
    "        # print(\"Warning: total state set is empty; using default penalty = 1.0\")\n",
    "        pen = 1.0\n",
    "    pen = pen * pen_multiplier\n",
    "\n",
    "    return alpha * js + (1 - alpha) * pen\n",
    "\n",
    "\n",
    "def build_distance_matrix(user_chains, alpha=0.5, pen_multiplier=1):\n",
    "    users = list(user_chains.keys())\n",
    "    n = len(users)\n",
    "    INF = float('inf')\n",
    "\n",
    "    # 1) Initialize the “direct” distance lookup\n",
    "    direct = { (u,v): (0.0 if u==v else INF)\n",
    "               for u in users for v in users }\n",
    "\n",
    "    # 2) Fill in distances for pairs with common states\n",
    "    for u1, u2 in combinations(users, 2):\n",
    "        dist = compute_js_and_penalty(user_chains[u1],\n",
    "                                      user_chains[u2],\n",
    "                                      alpha=alpha,\n",
    "                                      pen_multiplier=pen_multiplier)\n",
    "        if dist is not None:\n",
    "            direct[(u1,u2)] = direct[(u2,u1)] = dist\n",
    "\n",
    "    # 3) Build a graph whose edges are exactly those “direct” distances\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(users)\n",
    "    for (u,v), w in direct.items():\n",
    "        if u != v and w < INF:\n",
    "            G.add_edge(u, v, weight=w)\n",
    "\n",
    "    # 4) Compute all‐pairs shortest paths on G\n",
    "    sp_lengths = dict(nx.all_pairs_dijkstra_path_length(G, weight='weight'))\n",
    "\n",
    "    # 5) Assemble full DataFrame\n",
    "    D = pd.DataFrame(INF, index=users, columns=users)\n",
    "    for u in users:\n",
    "        for v, d in sp_lengths[u].items():\n",
    "            D.at[u, v] = d\n",
    "\n",
    "    # 6) Count connected components (for reporting)\n",
    "    n_components = nx.number_connected_components(G)\n",
    "\n",
    "    # 7) Print fallback usage statistics\n",
    "    if js_eval_total > 0:\n",
    "        print(f\"JS fallback used in {100 * js_fallback_count / js_eval_total:.1f}% of cases\")\n",
    "    if pen_eval_total > 0:\n",
    "        print(f\"Penalty fallback used in {100 * pen_fallback_count / pen_eval_total:.1f}% of cases\")\n",
    "\n",
    "    return D, n_components\n",
    "\n",
    "\n",
    "dist_matrix, components = build_distance_matrix(user_chains, alpha=0.2,pen_multiplier=1)\n",
    "print(\"Distance matrix:\\n\", dist_matrix)\n",
    "print(\"Connected components:\", components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d30f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assume `dist_matrix` is a pandas DataFrame of shape (n_users, n_users)\n",
    "# with user IDs as both index and columns.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(dist_matrix.values)\n",
    "\n",
    "# Label axes with user IDs\n",
    "ax.set_xticks(range(len(dist_matrix.columns)))\n",
    "ax.set_xticklabels(dist_matrix.columns, rotation=90)\n",
    "ax.set_yticks(range(len(dist_matrix.index)))\n",
    "ax.set_yticklabels(dist_matrix.index)\n",
    "\n",
    "ax.set_title('User Distance Matrix Heatmap')\n",
    "\n",
    "# Add a colorbar to interpret distances\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afeac9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "activities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zduration_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58210778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# --- Step 1: Build the bipartite graph ---\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(common_users, bipartite='user')\n",
    "activities_list = list(\n",
    "    set(tuple(x) for x in zduration_sum[['course_id', 'activity_type']].to_numpy())\n",
    ")\n",
    "B.add_nodes_from(activities_list, bipartite='activity')\n",
    "\n",
    "for row in zduration_sum.itertuples(index=False):\n",
    "    B.add_edge(row.user_id, (row.course_id, row.activity_type), weight=row.zscore_duration)\n",
    "\n",
    "# --- Step 2: Build the user-user weighted graph based on shared activities ---\n",
    "G_user = nx.Graph()\n",
    "G_user.add_nodes_from(common_users)\n",
    "\n",
    "n_users = len(common_users)\n",
    "user_idx = {u: i for i, u in enumerate(common_users)}  # mapping for matrix\n",
    "\n",
    "for i in range(n_users):\n",
    "    for j in range(i + 1, n_users):\n",
    "        u1, u2 = common_users[i], common_users[j]\n",
    "        u1_acts = set(B.neighbors(u1))\n",
    "        u2_acts = set(B.neighbors(u2))\n",
    "        common_acts = u1_acts & u2_acts\n",
    "        if common_acts:\n",
    "            z1 = [B.edges[u1, act]['weight'] for act in common_acts]\n",
    "            z2 = [B.edges[u2, act]['weight'] for act in common_acts]\n",
    "            dist = np.linalg.norm(np.array(z1) - np.array(z2))\n",
    "            G_user.add_edge(u1, u2, weight=dist)\n",
    "\n",
    "# Use Floyd-Warshall for all-pairs shortest path in the user-user graph\n",
    "fw_matrix = nx.floyd_warshall_numpy(G_user, nodelist=common_users, weight='weight')\n",
    "# fw_matrix is a numpy array, shape (n_users, n_users), with shortest distances\n",
    "\n",
    "# Optionally, handle infinite distances (disconnected pairs)\n",
    "max_g = np.nanmax(fw_matrix[np.isfinite(fw_matrix)])\n",
    "fw_matrix = np.where(np.isfinite(fw_matrix), fw_matrix, max_g * 1.1)\n",
    "graph_matrix = fw_matrix\n",
    "\n",
    "\n",
    "# Optional: fill nans with a large value\n",
    "max_g = np.nanmax(graph_matrix[~np.isnan(graph_matrix)])\n",
    "graph_matrix = np.nan_to_num(graph_matrix, nan=max_g * 1.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e62857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ---- Minimal Example (for illustration) ----\n",
    "# Replace this with your real data as needed!\n",
    "sample_users = ['U1', 'U2', 'U3', 'U4']\n",
    "sample_acts = [('C1', 'A'), ('C1', 'B'), ('C2', 'A'), ('C2', 'C')]\n",
    "sample_edges = [\n",
    "    ('U1', ('C1', 'A'), 1.0),\n",
    "    ('U1', ('C2', 'A'), 0.7),\n",
    "    ('U2', ('C1', 'A'), 0.2),\n",
    "    ('U2', ('C1', 'B'), 1.2),\n",
    "    ('U3', ('C2', 'C'), -0.4),\n",
    "    ('U4', ('C2', 'C'), 0.5),\n",
    "    ('U4', ('C1', 'B'), 0.8),\n",
    "    ('U4', ('C2', 'A'), 0.1),\n",
    "]\n",
    "\n",
    "# --- Step 1: Bipartite Graph ---\n",
    "B = nx.Graph()\n",
    "B.add_nodes_from(sample_users, bipartite='user')\n",
    "B.add_nodes_from(sample_acts, bipartite='activity')\n",
    "for u, a, w in sample_edges:\n",
    "    B.add_edge(u, a, weight=w)\n",
    "\n",
    "# --- Step 2: User-User Weighted Graph ---\n",
    "G_user = nx.Graph()\n",
    "G_user.add_nodes_from(sample_users)\n",
    "\n",
    "for i in range(len(sample_users)):\n",
    "    for j in range(i + 1, len(sample_users)):\n",
    "        u1, u2 = sample_users[i], sample_users[j]\n",
    "        u1_acts = set(B.neighbors(u1))\n",
    "        u2_acts = set(B.neighbors(u2))\n",
    "        common_acts = u1_acts & u2_acts\n",
    "        if common_acts:\n",
    "            z1 = [B.edges[u1, act]['weight'] for act in common_acts]\n",
    "            z2 = [B.edges[u2, act]['weight'] for act in common_acts]\n",
    "            dist = np.linalg.norm(np.array(z1) - np.array(z2))\n",
    "            G_user.add_edge(u1, u2, weight=dist)\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 6))\n",
    "\n",
    "# 1. Bipartite\n",
    "ax = axes[0]\n",
    "user_nodes = [n for n, d in B.nodes(data=True) if d['bipartite']=='user']\n",
    "activity_nodes = [n for n, d in B.nodes(data=True) if d['bipartite']=='activity']\n",
    "\n",
    "pos = {}\n",
    "pos.update((u, (0, i)) for i, u in enumerate(user_nodes))\n",
    "pos.update((a, (1, i)) for i, a in enumerate(activity_nodes))\n",
    "nx.draw(B, pos, ax=ax, with_labels=True, node_color=['skyblue' if n in user_nodes else 'orange' for n in B.nodes()],\n",
    "        node_shape='o', edge_color='gray', width=2)\n",
    "nx.draw_networkx_nodes(\n",
    "    B, pos, nodelist=activity_nodes, \n",
    "    node_color='orange', \n",
    "    node_size=3000,\n",
    "    ax=ax\n",
    ")\n",
    "edge_labels = {(u, a): f\"{B.edges[u, a]['weight']:.1f}\" for u, a in B.edges()}\n",
    "nx.draw_networkx_edge_labels(B, pos, edge_labels=edge_labels, ax=ax, font_size=8)\n",
    "ax.set_title('Bipartite User-Activity Graph')\n",
    "ax.axis('off')\n",
    "\n",
    "# 2. User-User Graph with Shortest Path Highlighted\n",
    "ax2 = axes[1]\n",
    "user_pos = nx.circular_layout(G_user)\n",
    "nx.draw(G_user, user_pos, ax=ax2, with_labels=True, node_color='skyblue', node_size=600, edge_color='gray', width=2)\n",
    "edge_labels = {(u, v): f\"{G_user.edges[u, v]['weight']:.2f}\" for u, v in G_user.edges()}\n",
    "nx.draw_networkx_edge_labels(G_user, user_pos, edge_labels=edge_labels, ax=ax2, font_size=9)\n",
    "\n",
    "# Highlight a shortest path between two users\n",
    "u_start, u_end = 'U3', 'U1'\n",
    "path = nx.shortest_path(G_user, u_start, u_end, weight='weight')\n",
    "path_edges = list(zip(path[:-1], path[1:]))\n",
    "nx.draw_networkx_edges(G_user, user_pos, edgelist=path_edges, ax=ax2, width=5, edge_color='red')\n",
    "\n",
    "# Draw all edge labels\n",
    "edge_labels = {(u, v): f\"{G_user.edges[u, v]['weight']:.2f}\" for u, v in G_user.edges()}\n",
    "nx.draw_networkx_edge_labels(G_user, user_pos, edge_labels=edge_labels, ax=ax2, font_size=9)\n",
    "\n",
    "# Draw bold, visible labels on the red path\n",
    "for u, v in path_edges:\n",
    "    label = f\"{G_user.edges[u, v]['weight']:.2f}\"\n",
    "    x = (user_pos[u][0] + user_pos[v][0]) / 2\n",
    "    y = (user_pos[u][1] + user_pos[v][1]) / 2\n",
    "\n",
    "    ax2.set_title(f'User-User Graph\\nShortest path: {u_start} → {u_end} highlighted')\n",
    "\n",
    "ax2.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ca9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. zduration_sum Graph-based Distance\n",
    "# n_users = len(common_users)\n",
    "\n",
    "# B = nx.Graph()\n",
    "# B.add_nodes_from(common_users, bipartite='user')\n",
    "# activities_list = list(\n",
    "#     set(tuple(x) for x in zduration_sum[['course_id', 'activity_type']].to_numpy())\n",
    "# )\n",
    "# print(activities_list)\n",
    "# B.add_nodes_from(activities_list, bipartite='activity')\n",
    "\n",
    "# for row in zduration_sum.itertuples(index=False):\n",
    "#     B.add_edge(row.user_id, (row.course_id, row.activity_type), weight=row.zscore_duration)\n",
    "\n",
    "# graph_matrix = np.zeros((n_users, n_users))\n",
    "# for i in range(n_users):\n",
    "#     for j in range(i + 1, n_users):\n",
    "#         u1, u2 = common_users[i], common_users[j]\n",
    "#         u1_acts = set(B.neighbors(u1))\n",
    "#         u2_acts = set(B.neighbors(u2))\n",
    "#         common_acts = u1_acts & u2_acts\n",
    "#         if common_acts:\n",
    "#             z1 = [B.edges[u1, act]['weight'] for act in common_acts]\n",
    "#             z2 = [B.edges[u2, act]['weight'] for act in common_acts]\n",
    "#             dist = np.linalg.norm(np.array(z1) - np.array(z2))\n",
    "#         else:\n",
    "#             try:\n",
    "#                 path = nx.shortest_path(B, u1, u2)\n",
    "#                 edge_weights = []\n",
    "#                 for k in range(0, len(path) - 2, 2):\n",
    "#                     z1 = B.edges[path[k], path[k+1]]['weight']\n",
    "#                     z2 = B.edges[path[k+2], path[k+1]]['weight']\n",
    "#                     edge_weights.append(abs(z1 - z2))\n",
    "#                 dist = sum(edge_weights)\n",
    "#             except nx.NetworkXNoPath:\n",
    "#                 dist = np.nan\n",
    "#         graph_matrix[i, j] = graph_matrix[j, i] = dist\n",
    "\n",
    "# max_g = np.nanmax(graph_matrix[~np.isnan(graph_matrix)])\n",
    "# graph_matrix = np.nan_to_num(graph_matrix, nan=max_g * 1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e527d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.metrics import dtw\n",
    "\n",
    "# 2. gap_days DTW Distance Matrix\n",
    "gap_days_map = gap_days.set_index('user_id')['gap_days'].to_dict()\n",
    "gap_days_seqs = [gap_days_map[u] for u in common_users]\n",
    "dtw_matrix = np.zeros((n_users, n_users))\n",
    "for i in range(n_users):\n",
    "    for j in range(i + 1, n_users):\n",
    "        d = dtw(gap_days_seqs[i], gap_days_seqs[j])\n",
    "        dtw_matrix[i, j] = dtw_matrix[j, i] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92eef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Normalize and Combine\n",
    "def normalize_matrix(m):\n",
    "    # flat = m[np.triu_indices_from(m, 1)]\n",
    "    # m_norm = np.zeros_like(m)\n",
    "    # if flat.max() > flat.min():\n",
    "    #     m_norm = (m - flat.min()) / (flat.max() - flat.min())\n",
    "    # return m_norm\n",
    "    return (m - np.min(m)) / (np.max(m) - np.min(m))\n",
    "\n",
    "dtw_norm = normalize_matrix(dtw_matrix)\n",
    "graph_norm = normalize_matrix(graph_matrix)\n",
    "combined_matrix = (dtw_norm + 2*dist_matrix + graph_norm) / 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.cluster import SpectralClustering\n",
    "# from sklearn.manifold import spectral_embedding\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# from scipy.sparse.csgraph import laplacian\n",
    "# from scipy.linalg import eigh\n",
    "\n",
    "# # If combined_matrix is a DataFrame, turn it into a NumPy array:\n",
    "# dist = combined_matrix.values if hasattr(combined_matrix, \"values\") else combined_matrix\n",
    "\n",
    "# # ---- 1. compute local scales from your distance matrix ----\n",
    "# n = dist.shape[0]\n",
    "# k_local = min(7, n-1)\n",
    "# sorted_d = np.sort(dist, axis=1)\n",
    "# sigma = sorted_d[:, k_local]\n",
    "# sigma_i_j = np.outer(sigma, sigma)\n",
    "# affinity = np.exp(- dist**2 / sigma_i_j)\n",
    "\n",
    "# # ---- 2. compute normalized Laplacian eigengap ----\n",
    "# # Convert affinity to array as well, just in case:\n",
    "# A = affinity if isinstance(affinity, np.ndarray) else affinity.values\n",
    "# L = laplacian(A, normed=True)\n",
    "# eigvals, _ = eigh(L)\n",
    "# # compute gaps and pick best k up to say 10\n",
    "# max_k = min(10, n-1)\n",
    "# gaps = eigvals[1:max_k+1] - eigvals[:max_k]\n",
    "# best_n = np.argmax(gaps) + 1\n",
    "\n",
    "# print(f\"Selected number of clusters by eigengap: {best_n}\")\n",
    "\n",
    "# # ---- 3. (optional) sanity check with silhouette ----\n",
    "# labels = SpectralClustering(\n",
    "#     n_clusters=best_n,\n",
    "#     affinity='precomputed',\n",
    "#     random_state=42\n",
    "# ).fit_predict(affinity)\n",
    "\n",
    "# X_lap = spectral_embedding(\n",
    "#     adjacency=A,\n",
    "#     n_components=best_n,\n",
    "#     norm_laplacian=True\n",
    "# )\n",
    "# sil_emb = silhouette_score(X_lap, labels, metric='euclidean')\n",
    "# print(f\"Silhouette (embedding space): {sil_emb:.3f}\")\n",
    "\n",
    "# # (Optional) if you still want the raw-distance silhouette for comparison:\n",
    "# sil_raw = silhouette_score(dist, labels, metric='precomputed')\n",
    "# print(f\"Silhouette (raw distances):   {sil_raw:.3f}\")\n",
    "\n",
    "# # ---- 4. visualize the gap if you like ----\n",
    "# plt.figure(figsize=(6,4))\n",
    "# plt.plot(range(1, max_k+1), gaps, marker='o')\n",
    "# plt.axvline(best_n, color='red', linestyle='--', label=f'pick k={best_n}')\n",
    "# plt.xlabel('i (candidate #clusters)')\n",
    "# plt.ylabel('λ_{i+1} − λ_i (eigengap)')\n",
    "# plt.legend()\n",
    "# plt.title('Eigengap Heuristic for Self-Tuning Spectral Clustering')\n",
    "# plt.show()\n",
    "\n",
    "# # ---- 5. assemble your DataFrame ----\n",
    "# cluster_df = pd.DataFrame({\n",
    "#     'user_id': common_users,\n",
    "#     'cluster': labels\n",
    "# })\n",
    "# display(cluster_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d973572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95409304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert distance matrix to similarity (kernel trick: exp(-distance^2 / (2*sigma^2)))\n",
    "sigma = np.median(combined_matrix)\n",
    "similarity_matrix = np.exp(-combined_matrix ** 2 / (2.0 * sigma ** 2))\n",
    "\n",
    "range_n_clusters = range(2, min(11, len(common_users)))\n",
    "sil_scores = []\n",
    "best_score = -1\n",
    "best_n = None\n",
    "best_labels = None\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=42)\n",
    "    labels = clustering.fit_predict(similarity_matrix)\n",
    "    # Silhouette expects a distance matrix, so use the original distance\n",
    "    score = silhouette_score(combined_matrix, labels, metric='precomputed')\n",
    "    sil_scores.append(score)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n_clusters\n",
    "        best_labels = labels\n",
    "\n",
    "print(f\"Best number of clusters: {best_n} (silhouette score: {best_score:.3f})\")\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.plot(list(range_n_clusters), sil_scores, marker='o')\n",
    "plt.title(\"Silhouette Score vs Number of Clusters (Spectral)\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.show()\n",
    "\n",
    "cluster_df = pd.DataFrame({\n",
    "    'user_id': common_users,\n",
    "    'cluster': best_labels\n",
    "})\n",
    "display(cluster_df)\n",
    "\n",
    "labels_spectral = best_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5265c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 1. build similarity exactly as before\n",
    "sigma = np.median(combined_matrix)\n",
    "similarity_matrix = np.exp(- combined_matrix**2 / (2.0 * sigma**2))\n",
    "\n",
    "# 2. try k = 2…10 (or up to number of users)\n",
    "range_n_clusters = range(2, min(11, len(common_users)))\n",
    "sil_scores = []\n",
    "best_score = -1\n",
    "best_n = None\n",
    "best_labels = None\n",
    "best_centroids = None\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    # run k-means on the rows of the similarity matrix\n",
    "    km = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = km.fit_predict(similarity_matrix)\n",
    "    \n",
    "    # silhouette on your original distance matrix\n",
    "    score = silhouette_score(combined_matrix, labels, metric='precomputed')\n",
    "    sil_scores.append(score)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_n = n_clusters\n",
    "        best_labels = labels\n",
    "        best_centroids = km.cluster_centers_\n",
    "\n",
    "# 3. report & plot\n",
    "print(f\"Best number of clusters (k-means): {best_n} (silhouette score: {best_score:.3f})\")\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.plot(list(range_n_clusters), sil_scores, marker='o')\n",
    "plt.title(\"Silhouette Score vs Number of Clusters (K-Means on Similarity)\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.show()\n",
    "\n",
    "# 4. assemble your DataFrame\n",
    "cluster_df = pd.DataFrame({\n",
    "    'user_id': common_users,\n",
    "    'cluster': best_labels\n",
    "})\n",
    "display(cluster_df)\n",
    "\n",
    "labels_kmeans = best_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ddc010",
   "metadata": {},
   "source": [
    "### Clustering agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921dbbad",
   "metadata": {},
   "source": [
    "Both the Adjusted Rand Index (ARI) and Normalized Mutual Information (NMI) between K-means and Spectral Clustering cluster assignments are 1.0 (the Silhouette score for best_n=2 clusters is also equal), indicating perfect agreement between the two methods for this choice of features and cluster number. This strong consistency suggests that the features may capture a robust underlying structure in the data that is recognized by both algorithms. Further validation follows later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ad738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "ari = adjusted_rand_score(labels_kmeans, labels_spectral)\n",
    "nmi = normalized_mutual_info_score(labels_kmeans, labels_spectral)\n",
    "\n",
    "print(ari)\n",
    "print(nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879df98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cceb54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume similarity_matrix and combined_matrix are DataFrames indexed and columned by user_id\n",
    "\n",
    "for k in range(best_n):\n",
    "    # Get all user_ids in this cluster\n",
    "    cluster_user_ids = cluster_df[cluster_df['cluster'] == k]['user_id']\n",
    "    if cluster_user_ids.empty:\n",
    "        continue\n",
    "\n",
    "    # Subset similarity matrix for these users\n",
    "    cluster_similarity = similarity_matrix.loc[cluster_user_ids, :]\n",
    "    cluster_similarity = cluster_similarity[cluster_user_ids]  # square matrix\n",
    "\n",
    "    # Find the most central user: row closest to cluster centroid (in similarity space)\n",
    "    # Get the centroid in the full similarity space, but only care about users in this cluster\n",
    "    cluster_centroid = best_centroids[k]\n",
    "    # cluster_similarity.values shape: (num_cluster_users, num_cluster_users)\n",
    "    # but centroid is full vector, so restrict to cluster_user_ids columns\n",
    "    centroid_restricted = pd.Series(cluster_centroid, index=similarity_matrix.columns).loc[cluster_user_ids].values\n",
    "    similarity_to_centroid = np.linalg.norm(cluster_similarity.values - centroid_restricted, axis=1)\n",
    "    min_idx_in_cluster = np.argmin(similarity_to_centroid)\n",
    "    central_user_id = cluster_user_ids.iloc[min_idx_in_cluster]\n",
    "\n",
    "    # For that user, find their closest neighbor (lowest distance in original combined_matrix within cluster, excluding self)\n",
    "    distances_from_central = combined_matrix.loc[central_user_id, cluster_user_ids]\n",
    "    # Exclude self by dropping central user\n",
    "    distances_no_self = distances_from_central.drop(central_user_id)\n",
    "    if not distances_no_self.empty:\n",
    "        closest_neighbor_user_id = distances_no_self.idxmin()\n",
    "    else:\n",
    "        closest_neighbor_user_id = None  # only one user in cluster\n",
    "\n",
    "    print(f\"Cluster {k}:\")\n",
    "    print(f\"  Most representative (central) user_id: {central_user_id}\")\n",
    "    print(f\"  Closest neighbor's user_id: {closest_neighbor_user_id}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42102a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d9b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# t-SNE works with similarities; precomputed metric expects a distance matrix\n",
    "tsne = TSNE(n_components=best_n, metric='precomputed', random_state=42, init='random')\n",
    "embeddings = tsne.fit_transform(combined_matrix)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    embeddings[:, 0], embeddings[:, 1],\n",
    "    c=best_labels, cmap='tab10', s=60, edgecolor='k'\n",
    ")\n",
    "plt.title(f\"User Clusters (t-SNE projection, {best_n} clusters)\", fontsize=15)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd30bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Single cell to compute centroids, find closest users, and store results\n",
    "\n",
    "# from sklearn.cluster import KMeans\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Re-fit KMeans with the best number of clusters (from your previous search)\n",
    "# best_km = KMeans(n_clusters=best_n, random_state=42)\n",
    "# best_km.fit(similarity_matrix)\n",
    "\n",
    "# # Extract centroids\n",
    "# centroids = best_km.cluster_centers_  # shape: (best_n, n_users)\n",
    "\n",
    "# # For each centroid, find the closest user\n",
    "# closest_user_indices = []\n",
    "# closest_users = []\n",
    "# for i, centroid in enumerate(centroids):\n",
    "#     # compute Euclidean distance between this centroid and each user vector\n",
    "#     dists = np.linalg.norm(similarity_matrix - centroid, axis=1)\n",
    "#     closest_idx = np.argmin(dists)\n",
    "#     closest_user_indices.append(closest_idx)\n",
    "#     closest_users.append(common_users[closest_idx])\n",
    "\n",
    "# # Prepare a DataFrame for easy viewing\n",
    "# centroid_df = pd.DataFrame({\n",
    "#     'cluster': range(best_n),\n",
    "#     'closest_user': closest_users,\n",
    "#     'user_index': closest_user_indices\n",
    "# })\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Cluster centroids and their closest users:\")\n",
    "# print(centroid_df.to_string(index=False))\n",
    "\n",
    "# # Variables you can now use:\n",
    "# # - centroids: array of shape (best_n, n_users)\n",
    "# # - closest_user_indices: list of indices into `common_users`\n",
    "# # - closest_users: list of user IDs closest to each centroid\n",
    "# # - centroid_df: DataFrame summarizing the above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae6f5d",
   "metadata": {},
   "source": [
    "## GUI to explore users' markov chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74898ba4",
   "metadata": {},
   "source": [
    "#### You can observe what each user's working on: user 22 for example is only doing long-time gymnasium essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "def plot_user_markov(user_id):\n",
    "    # --- pull out the transition matrix and states ---\n",
    "    mc     = user_chains[user_id]\n",
    "    P      = np.array(mc.p)\n",
    "    states = list(mc.states)\n",
    "\n",
    "    # --- build directed graph of all transitions ---\n",
    "    G = nx.DiGraph()\n",
    "    for i, u in enumerate(states):\n",
    "        for j, v in enumerate(states):\n",
    "            w = round(P[i, j], 2)\n",
    "            if w > 0:\n",
    "                G.add_edge(u, v, weight=w)\n",
    "    if G.number_of_edges() == 0:\n",
    "        print(f\"No transitions to plot for User {user_id}.\")\n",
    "        return\n",
    "\n",
    "    # --- compute stationary distribution π (left eigenvector for λ=1) ---\n",
    "    vals, vecs = np.linalg.eig(P.T)\n",
    "    idx1 = np.argmin(np.abs(vals - 1.0))\n",
    "    pi_raw = np.real(vecs[:, idx1])\n",
    "    pi = pi_raw / pi_raw.sum()\n",
    "    pi_map = {s: pi[states.index(s)] for s in states}\n",
    "\n",
    "    # --- position nodes (Graphviz neato, else spring) ---\n",
    "    try:\n",
    "        rawpos = graphviz_layout(G, prog='neato')\n",
    "    except:\n",
    "        rawpos = nx.spring_layout(G, seed=42)\n",
    "    xs = np.array([p[0] for p in rawpos.values()])\n",
    "    ys = np.array([p[1] for p in rawpos.values()])\n",
    "    minx, maxx = xs.min(), xs.max()\n",
    "    miny, maxy = ys.min(), ys.max()\n",
    "    pos = {\n",
    "        n: (\n",
    "            (rawpos[n][0] - minx) / (maxx - minx),\n",
    "            (rawpos[n][1] - miny) / (maxy - miny),\n",
    "        )\n",
    "        for n in G.nodes()\n",
    "    }\n",
    "\n",
    "    # --- draw edges + arrowheads ---\n",
    "    edge_traces = []\n",
    "    annotations  = []\n",
    "    marker_radius_px = 30   # half of marker.size=60\n",
    "\n",
    "    for u, v, data in G.edges(data=True):\n",
    "        x0, y0 = pos[u]\n",
    "        x1, y1 = pos[v]\n",
    "        w       = data['weight']\n",
    "\n",
    "        # curved if bidirectional\n",
    "        rad = 0.2 if G.has_edge(v, u) and u != v else 0.0\n",
    "        cx = 0.5*(x0+x1) + rad*(y1-y0)\n",
    "        cy = 0.5*(y0+y1) + rad*(x0-x1)\n",
    "\n",
    "        # main line\n",
    "        edge_traces.append(go.Scatter(\n",
    "            x=[x0, cx, x1], y=[y0, cy, y1],\n",
    "            mode='lines',\n",
    "            line=dict(color='rgba(100,100,100,0.5)', width=1.5, shape='spline'),\n",
    "            hoverinfo='none', showlegend=False\n",
    "        ))\n",
    "\n",
    "        # weight label\n",
    "        annotations.append(dict(\n",
    "            x=cx, y=cy, text=f\"{w:.2f}\",\n",
    "            showarrow=False,\n",
    "            font=dict(size=11),\n",
    "            bgcolor='rgba(255,255,255,0.8)',\n",
    "            borderpad=2\n",
    "        ))\n",
    "\n",
    "        # arrowhead at 90% along the curve\n",
    "        t = 0.9\n",
    "        ax = (1-t)**2 * x0 + 2*(1-t)*t * cx + t**2 * x1\n",
    "        ay = (1-t)**2 * y0 + 2*(1-t)*t * cy + t**2 * y1\n",
    "\n",
    "        annotations.append(dict(\n",
    "            ax=ax, ay=ay,\n",
    "            x=x1, y=y1,\n",
    "            axref='x', ayref='y',\n",
    "            xref='x', yref='y',\n",
    "            showarrow=True,\n",
    "            arrowhead=2,\n",
    "            arrowsize=1.2,\n",
    "            arrowwidth=1.2,\n",
    "            arrowcolor='rgba(100,100,100,0.6)',\n",
    "            standoff=marker_radius_px\n",
    "        ))\n",
    "\n",
    "    # --- draw nodes ---\n",
    "    palette = px.colors.qualitative.Plotly\n",
    "    node_traces = []\n",
    "    for i, n in enumerate(G.nodes()):\n",
    "        x, y = pos[n]\n",
    "        color = palette[i % len(palette)]\n",
    "        node_traces.append(go.Scatter(\n",
    "            x=[x], y=[y],\n",
    "            mode='markers+text',\n",
    "            marker=dict(size=60, color=color, line=dict(width=2, color='darkblue')),\n",
    "            text=[f\"{pi_map[n]:.2f}\"],\n",
    "            textposition='middle center',\n",
    "            textfont=dict(size=12, color='black'),\n",
    "            name=n,\n",
    "            showlegend=True,\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "\n",
    "    # --- assemble figure ---\n",
    "    fig = go.Figure(\n",
    "        data=edge_traces + node_traces,\n",
    "        layout=go.Layout(\n",
    "            title=f\"User {user_id} Markov Model\",\n",
    "            title_x=0.5,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=1.02, y=1, bordercolor='lightgray', borderwidth=1),\n",
    "            margin=dict(t=50, l=25, r=150, b=25),\n",
    "            hovermode='closest',\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            annotations=annotations,\n",
    "            width=850, height=600,\n",
    "            plot_bgcolor='rgba(245,250,255,0.5)'\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# --- interactive widget boilerplate ---\n",
    "user_selector = widgets.Dropdown(\n",
    "    options=sorted(user_chains.keys()),\n",
    "    description='User:',\n",
    "    continuous_update=False\n",
    ")\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_change(change):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        plot_user_markov(change['new'])\n",
    "\n",
    "user_selector.observe(on_change, names='value')\n",
    "display(user_selector, out)\n",
    "\n",
    "# auto-plot the first user to start\n",
    "user_selector.value = sorted(user_chains.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc428937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "def plot_user_markov_with_edge_labels(user_id):\n",
    "    mc = user_chains[user_id]\n",
    "    matrix = np.array(mc.p)\n",
    "    states = mc.states\n",
    "\n",
    "    # Identify non-trivial states\n",
    "    non_trivial_states = set()\n",
    "    for i, state in enumerate(states):\n",
    "        row = matrix[i]\n",
    "        col = matrix[:, i]\n",
    "        if not (np.isclose(row[i], 1.0) and np.isclose(row.sum(), 1.0) and np.isclose(col.sum(), 1.0)):\n",
    "            non_trivial_states.add(state)\n",
    "\n",
    "    # Build filtered graph\n",
    "    G = nx.DiGraph()\n",
    "    for i, from_state in enumerate(states):\n",
    "        if from_state not in non_trivial_states:\n",
    "            continue\n",
    "        for j, to_state in enumerate(states):\n",
    "            if to_state in non_trivial_states and matrix[i, j] > 0:\n",
    "                G.add_edge(from_state, to_state, weight=round(matrix[i, j], 2))\n",
    "\n",
    "    if len(G.nodes) == 0:\n",
    "        print(f\"No significant transitions to visualize for User {user_id}.\")\n",
    "        return\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42)  # Better separation\n",
    "\n",
    "    edge_traces = []\n",
    "    edge_annotations = []\n",
    "\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        weight = edge[2]['weight']\n",
    "\n",
    "        # Compute curvature offset\n",
    "        offset = 0.1 if G.has_edge(edge[1], edge[0]) and edge[0] != edge[1] else 0\n",
    "        ctrl_x = (x0 + x1) / 2 + offset * (y1 - y0)\n",
    "        ctrl_y = (y0 + y1) / 2 + offset * (x0 - x1)\n",
    "\n",
    "        curve_x = [x0, ctrl_x, x1]\n",
    "        curve_y = [y0, ctrl_y, y1]\n",
    "\n",
    "        edge_traces.append(go.Scatter(\n",
    "            x=curve_x, y=curve_y,\n",
    "            line=dict(width=2, color='gray', shape='spline'),\n",
    "            mode='lines',\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "\n",
    "        # Label near the curve's control point\n",
    "        edge_annotations.append(dict(\n",
    "            x=ctrl_x, y=ctrl_y,\n",
    "            xref='x', yref='y',\n",
    "            text=f\"{weight}\",\n",
    "            showarrow=False,\n",
    "            font=dict(color='black', size=14),\n",
    "            bgcolor='rgba(255, 255, 255, 0.7)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            borderpad=2,\n",
    "            align='center',\n",
    "            opacity=0.9\n",
    "        ))\n",
    "\n",
    "        # Arrow at the end\n",
    "        edge_annotations.append(dict(\n",
    "            ax=ctrl_x, ay=ctrl_y,\n",
    "            x=x1, y=y1,\n",
    "            axref='x', ayref='y',\n",
    "            xref='x', yref='y',\n",
    "            showarrow=True,\n",
    "            arrowhead=3,\n",
    "            arrowsize=2,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='gray',\n",
    "            opacity=0.8\n",
    "        ))\n",
    "\n",
    "    # Node Trace\n",
    "    node_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in G.nodes()],\n",
    "        y=[pos[node][1] for node in G.nodes()],\n",
    "        text=list(G.nodes()),\n",
    "        mode='markers+text',\n",
    "        textposition='middle center',\n",
    "        marker=dict(size=60, color='lightblue', line=dict(width=3, color='darkblue'))\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=edge_traces + [node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title=f\"User {user_id} Markov Model (Non-Trivial States)\",\n",
    "                        title_x=0.5,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(t=50, l=25, r=25, b=25),\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        annotations=edge_annotations,\n",
    "                        width=800,\n",
    "                        height=600\n",
    "                    ))\n",
    "    fig.show()\n",
    "\n",
    "# Interactive widget\n",
    "user_selector = widgets.Dropdown(\n",
    "    options=sorted(user_chains.keys()),\n",
    "    description='User ID:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_user_change(change):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        plot_user_markov_with_edge_labels(change['new'])\n",
    "\n",
    "user_selector.observe(on_user_change, names='value')\n",
    "\n",
    "display(user_selector, out)\n",
    "\n",
    "# Auto-trigger initial plot\n",
    "user_selector.value = sorted(user_chains.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9650397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e5c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b40aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import networkx as nx\n",
    "# import numpy as np\n",
    "# from scipy.spatial.distance import jensenshannon\n",
    "# from itertools import combinations\n",
    "\n",
    "# def compute_js_divergence(p_chain, q_chain, common_states):\n",
    "#     \"\"\"\n",
    "#     Jensen–Shannon divergence on the subchain induced by common_states.\n",
    "#     If no valid rows (all zeros), returns 1.0 (max divergence).\n",
    "#     \"\"\"\n",
    "#     if not common_states:\n",
    "#         return None\n",
    "\n",
    "#     # Get indices of common states in each chain\n",
    "#     p_indices = [p_chain.states.index(s) for s in common_states]\n",
    "#     q_indices = [q_chain.states.index(s) for s in common_states]\n",
    "\n",
    "#     # Extract the transition submatrices\n",
    "#     P_sub = p_chain.p[np.ix_(p_indices, p_indices)]\n",
    "#     Q_sub = q_chain.p[np.ix_(q_indices, q_indices)]\n",
    "\n",
    "#     js_vals = []\n",
    "#     for row_p, row_q in zip(P_sub, Q_sub):\n",
    "#         # Only compute JS if both rows form valid distributions\n",
    "#         if row_p.sum() > 0 and row_q.sum() > 0:\n",
    "#             js_vals.append(jensenshannon(row_p, row_q, base=2))\n",
    "#     return float(np.nanmean(js_vals)) if js_vals else 1.0\n",
    "\n",
    "# def compute_penalty(p_chain, q_chain, common_states):\n",
    "#     \"\"\"\n",
    "#     Simple structural penalty: fraction of non-overlapping states.\n",
    "#     \"\"\"\n",
    "#     all_states = set(p_chain.states) | set(q_chain.states)\n",
    "#     overlap = len(common_states)\n",
    "#     return 1 - (overlap / len(all_states)) if all_states else 1.0\n",
    "\n",
    "# def compute_shortest_path_sum(chain):\n",
    "#     \"\"\"\n",
    "#     Sum of all-pairs shortest path lengths in the directed graph\n",
    "#     induced by positive-probability transitions.\n",
    "#     \"\"\"\n",
    "#     G = nx.DiGraph()\n",
    "#     for i, src in enumerate(chain.states):\n",
    "#         for j, dst in enumerate(chain.states):\n",
    "#             if chain.p[i, j] > 0:\n",
    "#                 G.add_edge(src, dst, weight=1)\n",
    "#     lengths = dict(nx.all_pairs_shortest_path_length(G))\n",
    "#     return sum(sum(d.values()) for d in lengths.values())\n",
    "\n",
    "# def build_user_graph(user_chains, alpha=0.5, threshold=None):\n",
    "#     \"\"\"\n",
    "#     Constructs an undirected graph where nodes are user_ids and\n",
    "#     edge‐weights are distances as described.\n",
    "#     \"\"\"\n",
    "#     G = nx.Graph()\n",
    "#     # add users as nodes\n",
    "#     for uid in user_chains:\n",
    "#         G.add_node(uid)\n",
    "\n",
    "#     # pairwise distances\n",
    "#     for (u1, c1), (u2, c2) in combinations(user_chains.items(), 2):\n",
    "#         common = set(c1.states) & set(c2.states)\n",
    "#         if common:\n",
    "#             js = compute_js_divergence(c1, c2, common)\n",
    "#             pen = compute_penalty(c1, c2, common)\n",
    "#             dist = alpha * js + (1 - alpha) * pen\n",
    "#         else:\n",
    "#             # no overlap → sum of each chain's path‐sum\n",
    "#             dist = compute_shortest_path_sum(c1) + compute_shortest_path_sum(c2)\n",
    "\n",
    "#         # optionally filter out very large distances\n",
    "#         if threshold is None or dist <= threshold:\n",
    "#             G.add_edge(u1, u2, weight=dist)\n",
    "\n",
    "#     return G\n",
    "\n",
    "# # --- Example usage ---------------------------------------------\n",
    "\n",
    "# # Suppose user_chains is already populated:\n",
    "# #   user_chains = {\n",
    "# #       \"alice\": MarkovChain(...),\n",
    "# #       \"bob\":   MarkovChain(...),\n",
    "# #       ...\n",
    "# #   }\n",
    "\n",
    "# G = build_user_graph(user_chains, alpha=0.7, threshold=10.0)\n",
    "# print(\"Number of connected components:\", nx.number_connected_components(G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033410b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nx.connected_components(G))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fef237",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0ca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "zduration_sum.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f01e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_days.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209490c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0b7e643",
   "metadata": {},
   "source": [
    "#### Compute distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c1ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc17add",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import networkx as nx\n",
    "# from tslearn.metrics import dtw\n",
    "# from scipy.spatial.distance import jensenshannon\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 1. Prepare user list (already aligned)\n",
    "# chains_users = set(user_chains.keys())\n",
    "\n",
    "# # which users have gap_days?\n",
    "# gap_users    = set(gap_days['user_id'])\n",
    "\n",
    "# # which users have duration z‐scores?\n",
    "# z_users      = set(zduration_sum['user_id'])\n",
    "\n",
    "# # only keep those who have all three\n",
    "# users_all = sorted(chains_users & gap_users & z_users)\n",
    "\n",
    "# n_users = len(users_all)\n",
    "# user_to_idx = {user: i for i, user in enumerate(users_all)}\n",
    "\n",
    "# # 2. gap_days DTW Distance Matrix\n",
    "# gap_days_map = gap_days.set_index('user_id')['gap_days'].to_dict()\n",
    "# gap_days_seqs = [gap_days_map[u] for u in users_all]\n",
    "# dtw_matrix = np.zeros((n_users, n_users))\n",
    "# for i in range(n_users):\n",
    "#     for j in range(i + 1, n_users):\n",
    "#         d = dtw(gap_days_seqs[i], gap_days_seqs[j])\n",
    "#         dtw_matrix[i, j] = dtw_matrix[j, i] = d\n",
    "\n",
    "# # 3. user_chains Jensen-Shannon Distance\n",
    "# user_stat_dists = [user_chains[u].steady_states[0] for u in users_all]\n",
    "# jsd_matrix = np.zeros((n_users, n_users))\n",
    "# for i in range(n_users):\n",
    "#     for j in range(i + 1, n_users):\n",
    "#         d = jensenshannon(user_stat_dists[i], user_stat_dists[j])\n",
    "#         jsd_matrix[i, j] = jsd_matrix[j, i] = d\n",
    "\n",
    "# # 4. zduration_sum Graph-based Distance\n",
    "# B = nx.Graph()\n",
    "# B.add_nodes_from(users_all, bipartite='user')\n",
    "# activities = list(\n",
    "#     set(tuple(x) for x in zduration_sum[['course_id', 'activity_type']].to_numpy())\n",
    "# )\n",
    "# B.add_nodes_from(activities, bipartite='activity')\n",
    "\n",
    "# for row in zduration_sum.itertuples(index=False):\n",
    "#     B.add_edge(row.user_id, (row.course_id, row.activity_type), weight=row.zscore_duration)\n",
    "\n",
    "# graph_matrix = np.zeros((n_users, n_users))\n",
    "# for i in range(n_users):\n",
    "#     for j in range(i + 1, n_users):\n",
    "#         u1, u2 = users_all[i], users_all[j]\n",
    "#         u1_acts = set(B.neighbors(u1))\n",
    "#         u2_acts = set(B.neighbors(u2))\n",
    "#         common_acts = u1_acts & u2_acts\n",
    "#         if common_acts:\n",
    "#             z1 = [B.edges[u1, act]['weight'] for act in common_acts]\n",
    "#             z2 = [B.edges[u2, act]['weight'] for act in common_acts]\n",
    "#             dist = np.linalg.norm(np.array(z1) - np.array(z2))\n",
    "#         else:\n",
    "#             try:\n",
    "#                 path = nx.shortest_path(B, u1, u2)\n",
    "#                 edge_weights = []\n",
    "#                 for k in range(0, len(path) - 2, 2):\n",
    "#                     z1 = B.edges[path[k], path[k+1]]['weight']\n",
    "#                     z2 = B.edges[path[k+2], path[k+1]]['weight']\n",
    "#                     edge_weights.append(abs(z1 - z2))\n",
    "#                 dist = sum(edge_weights)\n",
    "#             except nx.NetworkXNoPath:\n",
    "#                 dist = np.nan\n",
    "#         graph_matrix[i, j] = graph_matrix[j, i] = dist\n",
    "\n",
    "# max_g = np.nanmax(graph_matrix[~np.isnan(graph_matrix)])\n",
    "# graph_matrix = np.nan_to_num(graph_matrix, nan=max_g * 1.1)\n",
    "\n",
    "# # 5. Normalize and Combine\n",
    "# def normalize_matrix(m):\n",
    "#     flat = m[np.triu_indices_from(m, 1)]\n",
    "#     m_norm = np.zeros_like(m)\n",
    "#     if flat.max() > flat.min():\n",
    "#         m_norm = (m - flat.min()) / (flat.max() - flat.min())\n",
    "#     return m_norm\n",
    "\n",
    "# dtw_norm = normalize_matrix(dtw_matrix)\n",
    "# jsd_norm = normalize_matrix(jsd_matrix)\n",
    "# graph_norm = normalize_matrix(graph_matrix)\n",
    "# combined_matrix = (dtw_norm + jsd_norm + graph_norm) / 3.0\n",
    "\n",
    "# # # 6. Cluster\n",
    "# # n_clusters = 4  # You can change this number!\n",
    "# # clustering = AgglomerativeClustering(n_clusters=n_clusters, affinity='precomputed', linkage='average')\n",
    "# # labels = clustering.fit_predict(combined_matrix)\n",
    "\n",
    "# # # 7. t-SNE visualization of user clusters\n",
    "# # # t-SNE expects a similarity matrix, so we convert distance to similarity:\n",
    "# # similarity = np.exp(-combined_matrix / combined_matrix.std())\n",
    "\n",
    "# # tsne = TSNE(metric=\"precomputed\", random_state=42)\n",
    "# # embeddings = tsne.fit_transform(combined_matrix)\n",
    "\n",
    "# # plt.figure(figsize=(8, 6))\n",
    "# # scatter = plt.scatter(\n",
    "# #     embeddings[:, 0], embeddings[:, 1], c=labels, cmap='tab10', s=60, edgecolor='k'\n",
    "# # )\n",
    "# # plt.title('User Clusters (t-SNE projection)', fontsize=16)\n",
    "# # plt.xlabel('t-SNE 1')\n",
    "# # plt.ylabel('t-SNE 2')\n",
    "# # plt.colorbar(scatter, label='Cluster')\n",
    "# # plt.tight_layout()\n",
    "# # plt.show()\n",
    "\n",
    "# # # Optional: dataframe of cluster assignments\n",
    "# # cluster_df = pd.DataFrame({\n",
    "# #     'user_id': users_all,\n",
    "# #     'cluster': labels\n",
    "# # })\n",
    "# # display(cluster_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ff312",
   "metadata": {},
   "source": [
    "### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.cluster import SpectralClustering\n",
    "# from sklearn.metrics import silhouette_score\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Convert distance matrix to similarity (kernel trick: exp(-distance^2 / (2*sigma^2)))\n",
    "# sigma = np.median(combined_matrix)\n",
    "# similarity_matrix = np.exp(-combined_matrix ** 2 / (2.0 * sigma ** 2))\n",
    "\n",
    "# range_n_clusters = range(2, min(11, len(users_all)))\n",
    "# sil_scores = []\n",
    "# best_score = -1\n",
    "# best_n = None\n",
    "# best_labels = None\n",
    "\n",
    "# for n_clusters in range_n_clusters:\n",
    "#     clustering = SpectralClustering(n_clusters=n_clusters, affinity='precomputed', random_state=42)\n",
    "#     labels = clustering.fit_predict(similarity_matrix)\n",
    "#     # Silhouette expects a distance matrix, so use the original distance\n",
    "#     score = silhouette_score(combined_matrix, labels, metric='precomputed')\n",
    "#     sil_scores.append(score)\n",
    "#     if score > best_score:\n",
    "#         best_score = score\n",
    "#         best_n = n_clusters\n",
    "#         best_labels = labels\n",
    "\n",
    "# print(f\"Best number of clusters: {best_n} (silhouette score: {best_score:.3f})\")\n",
    "# plt.figure(figsize=(7, 4))\n",
    "# plt.plot(list(range_n_clusters), sil_scores, marker='o')\n",
    "# plt.title(\"Silhouette Score vs Number of Clusters (Spectral)\")\n",
    "# plt.xlabel(\"Number of clusters\")\n",
    "# plt.ylabel(\"Silhouette score\")\n",
    "# plt.show()\n",
    "\n",
    "# cluster_df = pd.DataFrame({\n",
    "#     'user_id': users_all,\n",
    "#     'cluster': best_labels\n",
    "# })\n",
    "# display(cluster_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b2925",
   "metadata": {},
   "source": [
    "### Visualize best clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a032141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# t-SNE works with similarities; precomputed metric expects a distance matrix\n",
    "tsne = TSNE(n_components=2, metric='precomputed', random_state=42, init='random')\n",
    "embeddings = tsne.fit_transform(combined_matrix)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(\n",
    "    embeddings[:, 0], embeddings[:, 1],\n",
    "    c=best_labels, cmap='tab10', s=60, edgecolor='k'\n",
    ")\n",
    "plt.title(f\"User Clusters (t-SNE projection, {best_n} clusters)\", fontsize=15)\n",
    "plt.xlabel('t-SNE 1')\n",
    "plt.ylabel('t-SNE 2')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415b9f61",
   "metadata": {},
   "source": [
    "## After clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03cba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_users_dict = (\n",
    "    cluster_df.groupby('cluster')['user_id']\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Now, cluster_users_dict[0] gives all user_ids in cluster 0, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of users per cluster: \" + \n",
    "      \", \".join(f\"Cluster {i}: {len(cluster_users_dict[i])}\" for i in range(best_n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average score per cluster\n",
    "\n",
    "i=0\n",
    "while i<best_n:\n",
    "    print(f\"Mean percentage for cluster {i} : {zscores[zscores['user_id'].isin(cluster_users_dict[i])].percentage.mean()}\")\n",
    "    print(f\"Median percentage for cluster {i} : {zscores[zscores['user_id'].isin(cluster_users_dict[i])].percentage.median()}\")\n",
    "\n",
    "    i+=1\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eee970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, best_n, figsize=(5 * best_n, 4), sharey=True)\n",
    "\n",
    "# If only one cluster, axes may not be a list\n",
    "if best_n == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i in range(best_n):\n",
    "    ax = axes[i]\n",
    "    cluster_users = cluster_users_dict[i]\n",
    "    data = zscores[zscores['user_id'].isin(cluster_users)]\n",
    "    \n",
    "    sns.histplot(\n",
    "        data=data, \n",
    "        x='percentage', \n",
    "        kde=True, \n",
    "        stat=\"density\",  # Normalize heights to compare shapes\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f'Cluster {i}')\n",
    "    ax.set_xlabel('Percentage')\n",
    "    ax.set_ylabel('Frequency' if i == 0 else '')  # Only leftmost plot shows Y-axis label\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f7164",
   "metadata": {},
   "source": [
    "### Median course durations per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e488e562",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while i<best_n:\n",
    "    print(f\"Median durations per course and activity type for cluster {i} : \")\n",
    "    plot_course_durations(\n",
    "    activities_copy[activities_copy['user_id'].isin(cluster_users_dict[i])]\n",
    "    .groupby(['course_id', 'activity_type'])['duration'].median().reset_index(),\n",
    "    course_map_short\n",
    ")\n",
    "    i+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597cad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get state order from any chain\n",
    "states = user_chains[users_all[0]].states\n",
    "n_states = len(states)\n",
    "\n",
    "cluster_avg_matrices = {}\n",
    "\n",
    "for cluster, user_ids in cluster_users_dict.items():\n",
    "    matrices = []\n",
    "    for uid in user_ids:\n",
    "        tmatrix = np.array(user_chains[uid].p)\n",
    "        matrices.append(tmatrix)\n",
    "    if matrices:\n",
    "        avg_matrix = np.mean(matrices, axis=0)\n",
    "        cluster_avg_matrices[cluster] = avg_matrix\n",
    "\n",
    "# Optional: Print or inspect\n",
    "for cluster, mat in cluster_avg_matrices.items():\n",
    "    print(f\"\\nCluster {cluster} average transition matrix:\\n{mat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cdfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "def plot_avg_markov_with_edge_labels(cluster_id, avg_matrix, states):\n",
    "    # Identify non-trivial states\n",
    "    non_trivial_states = set()\n",
    "    for i, state in enumerate(states):\n",
    "        row = avg_matrix[i]\n",
    "        col = avg_matrix[:, i]\n",
    "        if not (np.isclose(row[i], 1.0) and np.isclose(row.sum(), 1.0) and np.isclose(col.sum(), 1.0)):\n",
    "            non_trivial_states.add(state)\n",
    "\n",
    "    # Build filtered graph\n",
    "    G = nx.DiGraph()\n",
    "    for i, from_state in enumerate(states):\n",
    "        if from_state not in non_trivial_states:\n",
    "            continue\n",
    "        for j, to_state in enumerate(states):\n",
    "            if to_state in non_trivial_states and avg_matrix[i, j] > 0:\n",
    "                G.add_edge(from_state, to_state, weight=round(avg_matrix[i, j], 2))\n",
    "\n",
    "    if len(G.nodes) == 0:\n",
    "        print(f\"No significant transitions to visualize for Cluster {cluster_id}.\")\n",
    "        return\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    edge_traces = []\n",
    "    edge_annotations = []\n",
    "\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        weight = edge[2]['weight']\n",
    "\n",
    "        offset = 0.1 if G.has_edge(edge[1], edge[0]) and edge[0] != edge[1] else 0\n",
    "        ctrl_x = (x0 + x1) / 2 + offset * (y1 - y0)\n",
    "        ctrl_y = (y0 + y1) / 2 + offset * (x0 - x1)\n",
    "\n",
    "        curve_x = [x0, ctrl_x, x1]\n",
    "        curve_y = [y0, ctrl_y, y1]\n",
    "\n",
    "        edge_traces.append(go.Scatter(\n",
    "            x=curve_x, y=curve_y,\n",
    "            line=dict(width=2, color='gray', shape='spline'),\n",
    "            mode='lines',\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "\n",
    "        edge_annotations.append(dict(\n",
    "            x=ctrl_x, y=ctrl_y,\n",
    "            xref='x', yref='y',\n",
    "            text=f\"{weight}\",\n",
    "            showarrow=False,\n",
    "            font=dict(color='black', size=14),\n",
    "            bgcolor='rgba(255, 255, 255, 0.7)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            borderpad=2,\n",
    "            align='center',\n",
    "            opacity=0.9\n",
    "        ))\n",
    "\n",
    "        edge_annotations.append(dict(\n",
    "            ax=ctrl_x, ay=ctrl_y,\n",
    "            x=x1, y=y1,\n",
    "            axref='x', ayref='y',\n",
    "            xref='x', yref='y',\n",
    "            showarrow=True,\n",
    "            arrowhead=3,\n",
    "            arrowsize=2,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='gray',\n",
    "            opacity=0.8\n",
    "        ))\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in G.nodes()],\n",
    "        y=[pos[node][1] for node in G.nodes()],\n",
    "        text=list(G.nodes()),\n",
    "        mode='markers+text',\n",
    "        textposition='middle center',\n",
    "        marker=dict(size=60, color='lightblue', line=dict(width=3, color='darkblue'))\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=edge_traces + [node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title=f\"Cluster {cluster_id} Average Markov Model (Non-Trivial States)\",\n",
    "                        title_x=0.5,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(t=50, l=25, r=25, b=25),\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        annotations=edge_annotations,\n",
    "                        width=800,\n",
    "                        height=600\n",
    "                    ))\n",
    "    fig.show()\n",
    "\n",
    "# Widget for cluster selection\n",
    "cluster_selector = widgets.Dropdown(\n",
    "    options=sorted(cluster_avg_matrices.keys()),\n",
    "    description='Cluster:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "states = user_chains[users_all[0]].states  # Use state labels from any chain\n",
    "\n",
    "def on_cluster_change(change):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        cluster_id = change['new']\n",
    "        avg_matrix = cluster_avg_matrices[cluster_id]\n",
    "        plot_avg_markov_with_edge_labels(cluster_id, avg_matrix, states)\n",
    "\n",
    "cluster_selector.observe(on_cluster_change, names='value')\n",
    "\n",
    "display(cluster_selector, out)\n",
    "cluster_selector.value = sorted(cluster_avg_matrices.keys())[0]  # Trigger first plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0363ca9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "prototype_users = {}\n",
    "for cluster, user_ids in cluster_users_dict.items():\n",
    "    avg_matrix = cluster_avg_matrices[cluster]\n",
    "    min_dist = float('inf')\n",
    "    best_uid = None\n",
    "    for uid in user_ids:\n",
    "        tmatrix = np.array(user_chains[uid].p)\n",
    "        dist = np.linalg.norm(tmatrix - avg_matrix)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            best_uid = uid\n",
    "    prototype_users[cluster] = best_uid\n",
    "\n",
    "print(\"Prototype user per cluster:\", prototype_users)\n",
    "\n",
    "# Optional: visualize each prototype user\n",
    "for cluster, uid in prototype_users.items():\n",
    "    print(f\"Cluster {cluster}: Prototype user {uid}\")\n",
    "    plot_user_markov_with_edge_labels(uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Find the two most similar and most different users in the dataset\n",
    "min_dist = float('inf')\n",
    "max_dist = float('-inf')\n",
    "most_similar_pair = None\n",
    "most_different_pair = None\n",
    "\n",
    "for i, j in itertools.combinations(range(len(users_all)), 2):\n",
    "    dist = combined_matrix[i, j]\n",
    "    if dist < min_dist:\n",
    "        min_dist = dist\n",
    "        most_similar_pair = (users_all[i], users_all[j])\n",
    "    if dist > max_dist:\n",
    "        max_dist = dist\n",
    "        most_different_pair = (users_all[i], users_all[j])\n",
    "\n",
    "print(f\"Most similar pair: {most_similar_pair}, distance={min_dist:.3f}\")\n",
    "print(f\"Most different pair: {most_different_pair}, distance={max_dist:.3f}\")\n",
    "\n",
    "# Visualize their Markov chains (or other features)\n",
    "for uid in most_similar_pair + most_different_pair:\n",
    "    plot_user_markov_with_edge_labels(uid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be612b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate average gap_days per user\n",
    "gap_days_avg = gap_days.set_index('user_id')['gap_days'].apply(np.mean)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cluster in sorted(cluster_users_dict.keys()):\n",
    "    user_ids = cluster_users_dict[cluster]\n",
    "    vals = gap_days_avg[user_ids]\n",
    "    sns.kdeplot(vals, label=f'Cluster {cluster}', fill=True)\n",
    "sns.kdeplot(gap_days_avg, color='k', linestyle='--', label='Overall', fill=False)\n",
    "plt.xlabel(\"Average gap_days\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"PDP-style Plot: Distribution of Average gap_days per Cluster\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b276d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Choose an activity_type to investigate, e.g. 'video'\n",
    "activity_types = zduration_sum['activity_type'].unique()\n",
    "\n",
    "for activity in activity_types:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    for cluster, user_ids in cluster_users_dict.items():\n",
    "        vals = zduration_sum[\n",
    "            (zduration_sum['user_id'].isin(user_ids)) & \n",
    "            (zduration_sum['activity_type'] == activity)\n",
    "        ]['zscore_duration']\n",
    "        if len(vals) > 0:\n",
    "            sns.kdeplot(vals, label=f'Cluster {cluster}', fill=True)\n",
    "    plt.xlabel(f\"zscore_duration for activity: {activity}\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(f\"PDP-style: zscore_duration for '{activity}' by cluster\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "def mc_entropy(mc):\n",
    "    tmatrix = np.array(mc.p)\n",
    "    # Row-wise entropy (one per state), average over all\n",
    "    return np.mean([entropy(row) for row in tmatrix if np.sum(row) > 0])\n",
    "\n",
    "entropy_per_user = {uid: mc_entropy(user_chains[uid]) for uid in users_all}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for cluster, user_ids in cluster_users_dict.items():\n",
    "    vals = [entropy_per_user[uid] for uid in user_ids]\n",
    "    sns.kdeplot(vals, label=f'Cluster {cluster}', fill=True)\n",
    "plt.xlabel(\"Average Markov Chain Entropy\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"PDP-style: Markov Chain Entropy per Cluster\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features\n",
    "gap_avg = gap_days.set_index('user_id')['gap_days'].apply(np.mean)\n",
    "zscore_avg = zduration_sum.groupby('user_id')['zscore_duration'].mean()\n",
    "\n",
    "# Prepare DataFrame\n",
    "pdp_df = pd.DataFrame({\n",
    "    'user_id': users_all,\n",
    "    'gap_days_avg': [gap_avg[u] for u in users_all],\n",
    "    'zscore_duration_avg': [zscore_avg[u] for u in users_all],\n",
    "    'cluster': [cluster_df.set_index('user_id').loc[u, 'cluster'] for u in users_all]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    data=pdp_df, x='gap_days_avg', y='zscore_duration_avg',\n",
    "    hue='cluster', palette='tab10'\n",
    ")\n",
    "plt.xlabel(\"Average gap_days\")\n",
    "plt.ylabel(\"Average zscore_duration\")\n",
    "plt.title(\"Joint PDP: gap_days vs zscore_duration by Cluster\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b92f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_id = zduration_sum['course_id'].unique()[0]  # pick a course_id, or loop\n",
    "activity_type = 'quiz'  # or any activity_type\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "data = []\n",
    "for cluster, user_ids in cluster_users_dict.items():\n",
    "    vals = zduration_sum[\n",
    "        (zduration_sum['user_id'].isin(user_ids)) &\n",
    "        (zduration_sum['activity_type'] == activity_type) &\n",
    "        (zduration_sum['course_id'] == course_id)\n",
    "    ]['zscore_duration']\n",
    "    for v in vals:\n",
    "        data.append({'cluster': cluster, 'zscore_duration': v})\n",
    "\n",
    "sns.boxplot(\n",
    "    data=pd.DataFrame(data),\n",
    "    x='cluster', y='zscore_duration', palette='tab10'\n",
    ")\n",
    "plt.title(f\"PDP-style: zscore_duration for '{activity_type}' in course {course_id}\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"zscore_duration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56036bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_id = zduration_sum['course_id'].unique()[0]  # pick a course_id, or loop\n",
    "activity_type = 'lesson'  # or any activity_type\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "data = []\n",
    "for cluster, user_ids in cluster_users_dict.items():\n",
    "    vals = zduration_sum[\n",
    "        (zduration_sum['user_id'].isin(user_ids)) &\n",
    "        (zduration_sum['activity_type'] == activity_type) &\n",
    "        (zduration_sum['course_id'] == course_id)\n",
    "    ]['zscore_duration']\n",
    "    for v in vals:\n",
    "        data.append({'cluster': cluster, 'zscore_duration': v})\n",
    "\n",
    "sns.boxplot(\n",
    "    data=pd.DataFrame(data),\n",
    "    x='cluster', y='zscore_duration', palette='tab10'\n",
    ")\n",
    "plt.title(f\"PDP-style: zscore_duration for '{activity_type}' in course {course_id}\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"zscore_duration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_id = zduration_sum['course_id'].unique()[0]  # pick a course_id, or loop\n",
    "activity_type = 'topic'  # or any activity_type\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "data = []\n",
    "for cluster, user_ids in cluster_users_dict.items():\n",
    "    vals = zduration_sum[\n",
    "        (zduration_sum['user_id'].isin(user_ids)) &\n",
    "        (zduration_sum['activity_type'] == activity_type) &\n",
    "        (zduration_sum['course_id'] == course_id)\n",
    "    ]['zscore_duration']\n",
    "    for v in vals:\n",
    "        data.append({'cluster': cluster, 'zscore_duration': v})\n",
    "\n",
    "sns.boxplot(\n",
    "    data=pd.DataFrame(data),\n",
    "    x='cluster', y='zscore_duration', palette='tab10'\n",
    ")\n",
    "plt.title(f\"PDP-style: zscore_duration for '{activity_type}' in course {course_id}\")\n",
    "plt.xlabel(\"Cluster\")\n",
    "plt.ylabel(\"zscore_duration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b21791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each cluster, find the most probable transition in avg Markov\n",
    "for cluster, avg_matrix in cluster_avg_matrices.items():\n",
    "    max_idx = np.unravel_index(np.argmax(avg_matrix), avg_matrix.shape)\n",
    "    from_state, to_state = states[max_idx[0]], states[max_idx[1]]\n",
    "    prob = avg_matrix[max_idx]\n",
    "    print(f\"Cluster {cluster}: Most probable transition: {from_state} → {to_state} (p={prob:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983310f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "max_len = max(len(seq) for seq in gap_days['gap_days'])\n",
    "gap_days_map = gap_days.set_index('user_id')['gap_days'].to_dict()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for cluster, user_ids in cluster_users_dict.items():\n",
    "    aligned = []\n",
    "    for uid in user_ids:\n",
    "        seq = gap_days_map[uid]\n",
    "        padded = np.full(max_len, np.nan)\n",
    "        padded[:len(seq)] = seq\n",
    "        aligned.append(padded)\n",
    "    aligned = np.vstack(aligned)\n",
    "    mean_per_pos = np.nanmean(aligned, axis=0)\n",
    "    std_per_pos = np.nanstd(aligned, axis=0)\n",
    "    plt.plot(range(1, max_len + 1), mean_per_pos, label=f'Cluster {cluster}')\n",
    "    plt.fill_between(range(1, max_len + 1), mean_per_pos - std_per_pos, mean_per_pos + std_per_pos, alpha=0.2)\n",
    "\n",
    "plt.xlabel('Gap Index (order in sequence)')\n",
    "plt.ylabel('gap_days')\n",
    "plt.title('Alignment Plot: Average gap_days per Sequence Position by Cluster')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee53d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pydtmc as dtmc\n",
    "from ipywidgets import interact\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Sample User Data ---\n",
    "users_sequences = {\n",
    "    \"Alice\": [\"Home\", \"Search\", \"Product\", \"Cart\", \"Checkout\"],\n",
    "    \"Bob\": [\"Home\", \"Search\", \"Home\", \"Product\"],\n",
    "    \"Charlie\": [\"Home\", \"Product\", \"Cart\", \"Home\"],\n",
    "}\n",
    "\n",
    "# --- Create Transition Matrix ---\n",
    "all_states = sorted({state for seq in users_sequences.values() for state in seq})\n",
    "state_idx = {state: i for i, state in enumerate(all_states)}\n",
    "\n",
    "transition_counts = np.zeros((len(all_states), len(all_states)))\n",
    "for seq in users_sequences.values():\n",
    "    for from_state, to_state in zip(seq[:-1], seq[1:]):\n",
    "        transition_counts[state_idx[from_state], state_idx[to_state]] += 1\n",
    "\n",
    "transition_matrix = np.zeros_like(transition_counts)\n",
    "for i in range(len(all_states)):\n",
    "    row_sum = transition_counts[i].sum()\n",
    "    if row_sum == 0:\n",
    "        transition_matrix[i, i] = 1.0\n",
    "    else:\n",
    "        transition_matrix[i] = transition_counts[i] / row_sum\n",
    "transition_matrix = np.round(transition_matrix, 10)\n",
    "\n",
    "# --- Create Markov Chain object for calculations (if needed) ---\n",
    "chain = dtmc.MarkovChain(transition_matrix, all_states)\n",
    "\n",
    "# --- Build the NetworkX Graph Manually ---\n",
    "def plot_markov_chain_networkx(transition_matrix, state_names):\n",
    "    G = nx.DiGraph()\n",
    "    for i, from_state in enumerate(state_names):\n",
    "        for j, to_state in enumerate(state_names):\n",
    "            prob = transition_matrix[i, j]\n",
    "            if prob > 0:\n",
    "                G.add_edge(from_state, to_state, weight=prob)\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=1000, node_color='skyblue', edgecolors='black')\n",
    "    nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
    "    nx.draw_networkx_edges(G, pos, arrows=True, arrowstyle='-|>', arrowsize=20, connectionstyle='arc3,rad=0.1')\n",
    "    edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
    "    plt.title(\"Markov Chain Transition Diagram\", fontsize=16)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_markov_chain_networkx(transition_matrix, all_states)\n",
    "\n",
    "# --- Animate User Sequences with Plotly ---\n",
    "def animate_user_sequence(user):\n",
    "    seq = users_sequences[user]\n",
    "    frames = []\n",
    "    for i in range(1, len(seq) + 1):\n",
    "        current_seq = seq[:i]\n",
    "        x = list(range(len(current_seq)))\n",
    "        frames.append(go.Frame(\n",
    "            data=[go.Scatter(\n",
    "                x=x, \n",
    "                y=current_seq, \n",
    "                mode=\"lines+markers\", \n",
    "                marker=dict(size=14), \n",
    "                line=dict(width=4)\n",
    "            )],\n",
    "            name=f\"Step {i}\"\n",
    "        ))\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[go.Scatter(\n",
    "            x=[0], \n",
    "            y=[seq[0]], \n",
    "            mode=\"lines+markers\", \n",
    "            marker=dict(size=14), \n",
    "            line=dict(width=4)\n",
    "        )],\n",
    "        layout=go.Layout(\n",
    "            title=f\"Action Sequence for {user}\",\n",
    "            xaxis=dict(title=\"Step\", tickmode='linear'),\n",
    "            yaxis=dict(title=\"State\"),\n",
    "            updatemenus=[dict(\n",
    "                type=\"buttons\",\n",
    "                showactive=False,\n",
    "                buttons=[\n",
    "                    dict(\n",
    "                        label=\"Play\",\n",
    "                        method=\"animate\",\n",
    "                        args=[None, {\"frame\": {\"duration\": 1000, \"redraw\": True}, \"fromcurrent\": True}]\n",
    "                    ),\n",
    "                    dict(\n",
    "                        label=\"Pause\",\n",
    "                        method=\"animate\",\n",
    "                        args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\", \"fromcurrent\": True}]\n",
    "                    )\n",
    "                ]\n",
    "            )]\n",
    "        ),\n",
    "        frames=frames\n",
    "    )\n",
    "\n",
    "    fig.update_layout(width=800, height=500)\n",
    "    fig.show()\n",
    "\n",
    "# --- Interactive Dropdown ---\n",
    "interact(animate_user_sequence, user=list(users_sequences.keys()));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Build a mapping for a given user\n",
    "def get_state_labels(user_id):\n",
    "    user_states_df = final_transitions[final_transitions['user_id'] == user_id]\n",
    "    # Assume you have a column with the state index in the Markov chain (e.g., 'state_index')\n",
    "    # If not, we match order with Markov chain's states!\n",
    "    if 'state_index' in user_states_df.columns:\n",
    "        idx_to_label = user_states_df.set_index('state_index')['activity_state'].to_dict()\n",
    "        return [idx_to_label[i] for i in sorted(idx_to_label.keys())]\n",
    "    else:\n",
    "        # fallback: Markov chain states in order correspond to unique activity_state in user_states_df\n",
    "        ordered_labels = user_states_df.drop_duplicates('activity_state')['activity_state'].tolist()\n",
    "        return ordered_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "def plot_user_markov_final_transitions(user_id):\n",
    "    mc = user_chains[user_id]\n",
    "    matrix = np.array(mc.p)\n",
    "    # Get labels for each state from final_transitions\n",
    "    node_labels = get_state_labels(user_id)\n",
    "    assert len(node_labels) == len(mc.states), \"Label/state mismatch!\"\n",
    "\n",
    "    # Build graph (show transitions with prob > 0.01)\n",
    "    G = nx.DiGraph()\n",
    "    for i, from_state in enumerate(node_labels):\n",
    "        for j, to_state in enumerate(node_labels):\n",
    "            prob = matrix[i, j]\n",
    "            if prob > 0.01:\n",
    "                G.add_edge(from_state, to_state, weight=round(prob, 2))\n",
    "\n",
    "    if len(G.nodes) == 0:\n",
    "        print(f\"No significant transitions to visualize for User {user_id}.\")\n",
    "        return\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "    edge_traces = []\n",
    "    edge_annotations = []\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        weight = edge[2]['weight']\n",
    "        offset = 0.13 if G.has_edge(edge[1], edge[0]) and edge[0] != edge[1] else 0\n",
    "        ctrl_x = (x0 + x1) / 2 + offset * (y1 - y0)\n",
    "        ctrl_y = (y0 + y1) / 2 + offset * (x0 - x1)\n",
    "        curve_x = [x0, ctrl_x, x1]\n",
    "        curve_y = [y0, ctrl_y, y1]\n",
    "        edge_traces.append(go.Scatter(\n",
    "            x=curve_x, y=curve_y,\n",
    "            line=dict(width=2, color='gray', shape='spline'),\n",
    "            mode='lines',\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "        edge_annotations.append(dict(\n",
    "            x=ctrl_x, y=ctrl_y,\n",
    "            xref='x', yref='y',\n",
    "            text=f\"{weight}\",\n",
    "            showarrow=False,\n",
    "            font=dict(color='black', size=13),\n",
    "            bgcolor='rgba(255,255,255,0.8)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            borderpad=1,\n",
    "            align='center',\n",
    "            opacity=0.9\n",
    "        ))\n",
    "        edge_annotations.append(dict(\n",
    "            ax=ctrl_x, ay=ctrl_y,\n",
    "            x=x1, y=y1,\n",
    "            axref='x', ayref='y',\n",
    "            xref='x', yref='y',\n",
    "            showarrow=True,\n",
    "            arrowhead=3,\n",
    "            arrowsize=2,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='gray',\n",
    "            opacity=0.75\n",
    "        ))\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in G.nodes()],\n",
    "        y=[pos[node][1] for node in G.nodes()],\n",
    "        text=list(G.nodes()),\n",
    "        mode='markers+text',\n",
    "        textposition='middle center',\n",
    "        marker=dict(size=70, color='lightpink', line=dict(width=4, color='darkred'))\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=edge_traces + [node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title=f\"User {user_id}: Markov Chain (Final Transitions)\",\n",
    "                        title_x=0.5,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(t=55, l=25, r=25, b=25),\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        annotations=edge_annotations,\n",
    "                        width=900,\n",
    "                        height=700\n",
    "                    ))\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9845561",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_selector = widgets.Dropdown(\n",
    "    options=sorted(user_chains.keys()),\n",
    "    description='User ID:',\n",
    "    continuous_update=False\n",
    ")\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_user_change(change):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        plot_user_markov_final_transitions(change['new'])\n",
    "\n",
    "user_selector.observe(on_user_change, names='value')\n",
    "\n",
    "display(user_selector, out)\n",
    "user_selector.value = sorted(user_chains.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_transitions.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd03111",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_chains[1].states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12af8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import networkx as nx\n",
    "import plotly.graph_objs as go\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "\n",
    "def plot_user_markovchain(user_id):\n",
    "    mc = user_chains[user_id]\n",
    "    matrix = np.array(mc.p)\n",
    "    node_labels = mc.states  # Already activity_type_courseShortName\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "    for i, from_state in enumerate(node_labels):\n",
    "        for j, to_state in enumerate(node_labels):\n",
    "            prob = matrix[i, j]\n",
    "            if prob > 0.01:\n",
    "                G.add_edge(from_state, to_state, weight=round(prob, 2))\n",
    "\n",
    "    if len(G.nodes) == 0:\n",
    "        print(f\"No significant transitions to visualize for User {user_id}.\")\n",
    "        return\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42)\n",
    "    edge_traces = []\n",
    "    edge_annotations = []\n",
    "\n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        weight = edge[2]['weight']\n",
    "        offset = 0.13 if G.has_edge(edge[1], edge[0]) and edge[0] != edge[1] else 0\n",
    "        ctrl_x = (x0 + x1) / 2 + offset * (y1 - y0)\n",
    "        ctrl_y = (y0 + y1) / 2 + offset * (x0 - x1)\n",
    "        curve_x = [x0, ctrl_x, x1]\n",
    "        curve_y = [y0, ctrl_y, y1]\n",
    "        edge_traces.append(go.Scatter(\n",
    "            x=curve_x, y=curve_y,\n",
    "            line=dict(width=2, color='gray', shape='spline'),\n",
    "            mode='lines',\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "        edge_annotations.append(dict(\n",
    "            x=ctrl_x, y=ctrl_y,\n",
    "            xref='x', yref='y',\n",
    "            text=f\"{weight}\",\n",
    "            showarrow=False,\n",
    "            font=dict(color='black', size=13),\n",
    "            bgcolor='rgba(255,255,255,0.8)',\n",
    "            bordercolor='black',\n",
    "            borderwidth=1,\n",
    "            borderpad=1,\n",
    "            align='center',\n",
    "            opacity=0.9\n",
    "        ))\n",
    "        edge_annotations.append(dict(\n",
    "            ax=ctrl_x, ay=ctrl_y,\n",
    "            x=x1, y=y1,\n",
    "            axref='x', ayref='y',\n",
    "            xref='x', yref='y',\n",
    "            showarrow=True,\n",
    "            arrowhead=3,\n",
    "            arrowsize=2,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='gray',\n",
    "            opacity=0.75\n",
    "        ))\n",
    "\n",
    "    node_trace = go.Scatter(\n",
    "        x=[pos[node][0] for node in G.nodes()],\n",
    "        y=[pos[node][1] for node in G.nodes()],\n",
    "        text=list(G.nodes()),\n",
    "        mode='markers+text',\n",
    "        textposition='middle center',\n",
    "        marker=dict(size=70, color='lightpink', line=dict(width=4, color='darkred'))\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=edge_traces + [node_trace],\n",
    "                    layout=go.Layout(\n",
    "                        title=f\"User {user_id}: Markov Chain\",\n",
    "                        title_x=0.5,\n",
    "                        showlegend=False,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(t=55, l=25, r=25, b=25),\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        annotations=edge_annotations,\n",
    "                        width=900,\n",
    "                        height=700\n",
    "                    ))\n",
    "    fig.show()\n",
    "\n",
    "# Interactive dropdown\n",
    "user_selector = widgets.Dropdown(\n",
    "    options=sorted(user_chains.keys()),\n",
    "    description='User ID:',\n",
    "    continuous_update=False\n",
    ")\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_user_change(change):\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        plot_user_markovchain(change['new'])\n",
    "\n",
    "user_selector.observe(on_user_change, names='value')\n",
    "\n",
    "display(user_selector, out)\n",
    "user_selector.value = sorted(user_chains.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c238c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc6421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gogymi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
